{
    "original": "Acoustic-prosodic entrainment refers to the phenomenon wherein individuals adjust their speech patterns to align with each other during conversation, significantly impacting conversational outcomes. Despite its importance, effectively modeling this nuanced behavior in spoken dialogue presents a challenge. This study introduces a clear definition for local entrainment in the speech realm and develops an algorithm for measuring it: acoustic-prosodic features that capture entrainment should exhibit maximum disparities between genuine dialogues involving two individuals and simulated dialogues created by randomly shuffling speaking turns between the original partners. The proposed method assesses local entrainment by quantifying alignment of behaviors on a turn-by-turn basis, projecting differences in acoustic-prosodic features between conversational partners onto a discriminative feature subspace that magnifies disparities between authentic and simulated conversations. The effectiveness of the approach is demonstrated through a Naive Bayes classifier, achieving a 72% classification accuracy in predicting conversational success levels in task-oriented dialogues, outperforming existing methods on the same conversational dataset.",
    "sampled": "Acoustic-prosodic entrainment refers to the phenomenon wherein individuals adjust their speech patterns to align with each other during conversation, considerably impacting conversational outcomes. Despite its importance, effectively modeling this nuanced behavior in spoken dialogue presents a challenge. This study introduces a clear definition for local entrainment in the speech realm and develops an algorithm for measuring it: acoustic-prosodic features that capture entrainment should exhibit maximum disparities between genuine dialogues involving two individuals and simulated dialogues created by randomly shuffling speaking turns between the original partners. The proposed method assesses local entrainment by quantifying alignment of behaviors on a turn-by-turn basis, projecting differences in acoustic-prosodic features between conversational partners onto a discriminative feature subspace that magnifies disparities between authentic and simulated conversations. The effectiveness of the approach is demonstrated through a Naive Bayes classifier, achieving a 72% classification accuracy in predicting conversational success levels in task-oriented dialogues, outperforming existing methods on the same conversational dataset.",
    "replacement_keys": [
        19
    ],
    "original_crit": 0.000536602339707315,
    "sampled_crit": 0.0005295670125633478,
    "original_llm_likelihood": 0.000536602339707315,
    "sampled_llm_likelihood": 0.0005295670125633478
}