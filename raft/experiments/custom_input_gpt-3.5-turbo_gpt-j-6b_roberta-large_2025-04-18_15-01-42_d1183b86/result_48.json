{
    "original": "Online repositories containing user-generated 3D shapes offer a wealth of surface, primitive, and geometric information, often organized hierarchically. Our framework introduces a novel approach for learning representations of 3D shapes that encapsulate the rich metadata present in these repositories, resulting in enhanced generalization for semantic segmentation tasks. The core of our methodology is a point embedding network that generates vector representations of 3D points to capture grouping hierarchies and tag data. Overcoming the challenges posed by noisy and variable data, we propose a tree-aware metric-learning strategy that yields learned embeddings conducive to superior performance on semantic segmentation tasks, particularly in scenarios with limited training data. Our method achieves a considerable reduction in relative error rates, showcasing a $10.2\\%$ improvement with just 8 training examples, and an $11.72\\%$ enhancement with 120 training examples on the ShapeNet semantic segmentation benchmark compared to training from scratch. Leveraging tag data further reduces the relative error by $12.8%$ with 8 training examples, without incurring additional labeling costs as the metadata is readily available.",
    "sampled": "Online repositories containing user-generated 3D shapes offer a wealth of surface, primitive, and geometric information, often organized hierarchically. Our framework introduces a novel approach for learning representations of 3D shapes that encapsulate the rich metadata present in these repositories, resulting in enhanced generalization for semantic segmentation tasks. The core of our methodology is a point embedding network that generates vector representations of 3D points to capture grouping hierarchies and tag data. Overcoming the challenges posed by noisy and variable data, we propose a tree-aware metric-learning strategy that yields learned embeddings conducive to superior performance on semantic segmentation tasks, particularly in scenarios with limited training data. Our method achieves a considerable reduction in relative error rates, showcasing a $10.2\\%$ improvement with just 8 training examples, and an $11.72\\%$ enhancement with 120 training examples on the ShapeNet semantic segmentation benchmark compared to training from scratch. Leveraging tag data further reduces the relative error by $12.8%$ with 8 training examples, without incurring additional labeling costs as the metadata is readily available.",
    "replacement_keys": [],
    "original_crit": 0.0008091172785498202,
    "sampled_crit": 0.0008091172785498202,
    "original_llm_likelihood": 0.0008091172785498202,
    "sampled_llm_likelihood": 0.0008091172785498202
}