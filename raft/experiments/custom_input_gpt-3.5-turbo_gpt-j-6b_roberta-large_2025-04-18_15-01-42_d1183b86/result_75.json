{
    "original": "Conversational machine reading systems facilitate user interactions by assisting in answering complex queries, such as determining eligibility for specific government benefits, based on procedural guidelines present in textual resources like government websites. In this context, a key challenge is the system's ability to extract decision rules from procedural text, comprehend conversational history, and generate appropriate user questions. Introducing the Entailment-driven Extract and Edit network (E3), a new conversational machine reading model, offers a solution that outperforms existing systems and BERT-based baselines on the ShARC conversational machine reading dataset. Notably, E3 enhances explainability by explicitly identifying information gaps that need to be addressed. The release of source code for the models and experiments further supports research and development in this domain, accessible at https://github.com/vzhong/e3.",
    "sampled": "Conversational machine reading systems facilitate user interactions by assisting in answering complex queries, such as determining eligibility for specific government benefits, based on procedural guidelines present in textual resources like government websites. In this context, a key challenge is the system's ability to extract decision rules from procedural text, comprehend conversational history, and generate appropriate user questions. Introducing the Entailment-driven Extract and Edit network (E3), a new conversational machine reading model, offers a solution that outperforms existing systems and BERT-based baselines on the ShARC conversational machine reading dataset. Notably, E3 enhances interpretability by explicitly identifying information gaps that need to be addressed. The release of source code for the models and experiments further supports research and development in this domain, accessible at https://github.com/vzhong/e3.",
    "replacement_keys": [
        91
    ],
    "original_crit": 0.12820278108119965,
    "sampled_crit": 0.11974877864122391,
    "original_llm_likelihood": 0.12820278108119965,
    "sampled_llm_likelihood": 0.11974877864122391
}