{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me3o6bKmyzRz"
      },
      "source": [
        "#RAFT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirenments"
      ],
      "metadata": {
        "id": "RAooKGRGztMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QgikApnoyYg7",
        "outputId": "8bfdb7e0-cd78-49f0-8e6b-ed616bc3b78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/raft\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-txw35zpe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-txw35zpe\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 4f58fc9c823c43b67a6ce1c44be28f8aecc3c8d9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11447297 sha256=e05dbe8ff633ade88b386a6cef6bfb1ff0ba00ac1260a240c4f4f42bd2b4f54e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8lgyqveb/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed transformers-4.52.0.dev0\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
            "Collecting anyio==4.6.2.post1 (from -r requirements.txt (line 2))\n",
            "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting certifi==2024.8.30 (from -r requirements.txt (line 3))\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.4.0 (from -r requirements.txt (line 4))\n",
            "  Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting click==8.1.7 (from -r requirements.txt (line 5))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting contourpy==1.3.0 (from -r requirements.txt (line 6))\n",
            "  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
            "Collecting dill==0.3.9 (from -r requirements.txt (line 8))\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.9.0)\n",
            "Collecting exceptiongroup==1.2.2 (from -r requirements.txt (line 10))\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting filelock==3.16.1 (from -r requirements.txt (line 11))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fonttools==4.54.1 (from -r requirements.txt (line 12))\n",
            "  Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec==2024.10.0 (from -r requirements.txt (line 13))\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting gensim==4.3.3 (from -r requirements.txt (line 14))\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.14.0)\n",
            "Collecting httpcore==1.0.6 (from -r requirements.txt (line 16))\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting httpx==0.27.2 (from -r requirements.txt (line 17))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub==0.26.2 (from -r requirements.txt (line 18))\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (3.10)\n",
            "Collecting importlib_resources==6.4.5 (from -r requirements.txt (line 20))\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 21))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jiter==0.7.0 (from -r requirements.txt (line 22))\n",
            "  Downloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (1.4.2)\n",
            "Collecting kiwisolver==1.4.7 (from -r requirements.txt (line 24))\n",
            "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (3.0.2)\n",
            "Collecting matplotlib==3.9.2 (from -r requirements.txt (line 26))\n",
            "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (1.3.0)\n",
            "Collecting networkx==3.2.1 (from -r requirements.txt (line 28))\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (3.9.1)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 30))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from -r requirements.txt (line 31))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from -r requirements.txt (line 32))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from -r requirements.txt (line 33))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from -r requirements.txt (line 34))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements.txt (line 35))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from -r requirements.txt (line 36))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from -r requirements.txt (line 37))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from -r requirements.txt (line 38))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from -r requirements.txt (line 39))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (2.21.5)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from -r requirements.txt (line 41))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (12.4.127)\n",
            "Collecting openai==1.54.3 (from -r requirements.txt (line 43))\n",
            "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (24.2)\n",
            "Collecting pillow==11.0.0 (from -r requirements.txt (line 45))\n",
            "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pydantic==2.9.2 (from -r requirements.txt (line 46))\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.23.4 (from -r requirements.txt (line 47))\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pyparsing==3.2.0 (from -r requirements.txt (line 48))\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 49))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 50)) (6.0.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 52)) (2.32.3)\n",
            "Collecting safetensors==0.4.5 (from -r requirements.txt (line 53))\n",
            "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.5.2 (from -r requirements.txt (line 54))\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting scipy==1.13.1 (from -r requirements.txt (line 55))\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six==1.16.0 (from -r requirements.txt (line 56))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open==7.0.5 (from -r requirements.txt (line 57))\n",
            "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (1.3.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 59)) (1.13.1)\n",
            "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 60))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken==0.8.0 (from -r requirements.txt (line 61))\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tokenizers==0.20.3 (from -r requirements.txt (line 62))\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tqdm==4.67.0 (from -r requirements.txt (line 63))\n",
            "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.46.2 (from -r requirements.txt (line 64))\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from -r requirements.txt (line 65))\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting typing_extensions==4.12.2 (from -r requirements.txt (line 66))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting urllib3==2.2.3 (from -r requirements.txt (line 67))\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting wrapt==1.16.0 (from -r requirements.txt (line 68))\n",
            "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: zipp==3.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 69)) (3.21.0)\n",
            "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fonttools-4.54.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, urllib3, typing_extensions, tqdm, threadpoolctl, six, safetensors, pyparsing, pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, kiwisolver, jiter, Jinja2, importlib_resources, fsspec, fonttools, filelock, exceptiongroup, dill, click, charset-normalizer, certifi, anyio, triton, smart-open, scipy, python-dateutil, pydantic_core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, contourpy, tiktoken, scikit-learn, pydantic, nvidia-cusolver-cu12, matplotlib, huggingface-hub, httpx, gensim, tokenizers, openai, transformers\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.9.0\n",
            "    Uninstalling jiter-0.9.0:\n",
            "      Successfully uninstalled jiter-0.9.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: importlib_resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.57.0\n",
            "    Uninstalling fonttools-4.57.0:\n",
            "      Successfully uninstalled fonttools-4.57.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.9.0\n",
            "    Uninstalling anyio-4.9.0:\n",
            "      Successfully uninstalled anyio-4.9.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pydantic_core\n",
            "    Found existing installation: pydantic_core 2.33.1\n",
            "    Uninstalling pydantic_core-2.33.1:\n",
            "      Successfully uninstalled pydantic_core-2.33.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.8\n",
            "    Uninstalling httpcore-1.0.8:\n",
            "      Successfully uninstalled httpcore-1.0.8\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.2\n",
            "    Uninstalling contourpy-1.3.2:\n",
            "      Successfully uninstalled contourpy-1.3.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.3\n",
            "    Uninstalling pydantic-2.11.3:\n",
            "      Successfully uninstalled pydantic-2.11.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.30.2\n",
            "    Uninstalling huggingface-hub-0.30.2:\n",
            "      Successfully uninstalled huggingface-hub-0.30.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.75.0\n",
            "    Uninstalling openai-1.75.0:\n",
            "      Successfully uninstalled openai-1.75.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.0.dev0\n",
            "    Uninstalling transformers-4.52.0.dev0:\n",
            "      Successfully uninstalled transformers-4.52.0.dev0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.10.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.1.0 which is incompatible.\n",
            "google-genai 1.10.0 requires anyio<5.0.0,>=4.8.0, but you have anyio 4.6.2.post1 which is incompatible.\n",
            "google-genai 1.10.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Jinja2-3.1.4 anyio-4.6.2.post1 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 contourpy-1.3.0 dill-0.3.9 exceptiongroup-1.2.2 filelock-3.16.1 fonttools-4.54.1 fsspec-2024.10.0 gensim-4.3.3 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.2 importlib_resources-6.4.5 jiter-0.7.0 kiwisolver-1.4.7 matplotlib-3.9.2 networkx-3.2.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-1.54.3 pillow-11.0.0 pydantic-2.9.2 pydantic_core-2.23.4 pyparsing-3.2.0 python-dateutil-2.9.0.post0 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.13.1 six-1.16.0 smart-open-7.0.5 threadpoolctl-3.5.0 tiktoken-0.8.0 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2 triton-3.1.0 typing_extensions-4.12.2 urllib3-2.2.3 wrapt-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "dateutil",
                  "kiwisolver",
                  "six"
                ]
              },
              "id": "a34e7e22294a4a898f5f80c00ab68cd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.9.3-py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (4.67.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2024.8.30)\n",
            "Downloading language_tool_python-2.9.3-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.9.3\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, bitsandbytes\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "Successfully installed bitsandbytes-0.45.5 triton-3.2.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/raft\n",
        "!pip install -U transformers huggingface-hub\n",
        "!pip install -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -r requirements.txt\n",
        "!pip install language-tool-python\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAFT - Synonym replacement"
      ],
      "metadata": {
        "id": "perYkRFxz1oU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCfsLwgj3O_O",
        "outputId": "0055abe7-bd98-4f0e-a43e-69eac6ed7c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.89it/s]\n",
            "\n",
            "Zamiana słów (próbka 96): 100% 22/22 [00:53<00:00,  2.05s/it]\u001b[A\n",
            "Przetwarzanie RAFT:  95% 96/101 [1:58:34<04:59, 59.97s/it]\n",
            "Zamiana słów (próbka 97):   0% 0/22 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 149.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 154.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.89it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):   5% 1/22 [00:03<01:11,  3.43s/it]\u001b[A\n",
            "Zamiana słów (próbka 97):   9% 2/22 [00:06<01:07,  3.37s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.11it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  14% 3/22 [00:10<01:04,  3.41s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.25it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  18% 4/22 [00:13<00:57,  3.20s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 183.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.80it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  23% 5/22 [00:14<00:43,  2.57s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.46it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  27% 6/22 [00:15<00:34,  2.17s/it]\u001b[A\n",
            "Zamiana słów (próbka 97):  32% 7/22 [00:18<00:33,  2.24s/it]\u001b[A\n",
            "Zamiana słów (próbka 97):  36% 8/22 [00:20<00:31,  2.26s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.74it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  41% 9/22 [00:22<00:27,  2.15s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.15it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  45% 10/22 [00:24<00:23,  1.98s/it]\u001b[A\n",
            "Zamiana słów (próbka 97):  50% 11/22 [00:27<00:26,  2.38s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 152.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 159.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 156.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 158.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 151.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 153.72it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  55% 12/22 [00:30<00:25,  2.55s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 151.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 153.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 161.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 159.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 160.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 159.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 162.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 158.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 160.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 158.32it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  59% 13/22 [00:33<00:23,  2.65s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 153.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.45it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  64% 14/22 [00:36<00:21,  2.69s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.93it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  68% 15/22 [00:37<00:16,  2.39s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.54it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  73% 16/22 [00:39<00:13,  2.22s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.99it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  77% 17/22 [00:41<00:10,  2.09s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.73it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  82% 18/22 [00:44<00:09,  2.39s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.51it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  86% 19/22 [00:46<00:06,  2.21s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.37it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  91% 20/22 [00:49<00:04,  2.47s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.89it/s]\n",
            "\n",
            "Zamiana słów (próbka 97):  95% 21/22 [00:51<00:02,  2.40s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.76it/s]\n",
            "\n",
            "Zamiana słów (próbka 97): 100% 22/22 [00:54<00:00,  2.68s/it]\u001b[A\n",
            "Przetwarzanie RAFT:  96% 97/101 [1:59:31<03:57, 59.30s/it]\n",
            "Zamiana słów (próbka 98):   0% 0/29 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.85it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):   3% 1/29 [00:02<01:00,  2.16s/it]\u001b[A\n",
            "Zamiana słów (próbka 98):   7% 2/29 [00:05<01:16,  2.83s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 144.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 151.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.51it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  10% 3/29 [00:07<01:07,  2.60s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.41it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  14% 4/29 [00:11<01:12,  2.89s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.91it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  17% 5/29 [00:14<01:14,  3.10s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.80it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  21% 6/29 [00:16<00:59,  2.59s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 178.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 186.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.23it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  24% 7/29 [00:18<00:55,  2.52s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.32it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  28% 8/29 [00:22<00:59,  2.82s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.29it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  31% 9/29 [00:25<01:00,  3.00s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.45it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  34% 10/29 [00:27<00:50,  2.65s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.84it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  38% 11/29 [00:30<00:51,  2.86s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.10it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  41% 12/29 [00:32<00:43,  2.55s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 177.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 154.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 152.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 149.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 219.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 150.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 155.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 144.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 152.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.82it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  45% 13/29 [00:34<00:40,  2.53s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 149.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.64it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  48% 14/29 [00:36<00:35,  2.36s/it]\u001b[A\n",
            "Zamiana słów (próbka 98):  52% 15/29 [00:38<00:28,  2.07s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 152.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 150.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 145.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.94it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  55% 16/29 [00:40<00:26,  2.06s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 182.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.93it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  59% 17/29 [00:43<00:28,  2.39s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.96it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  62% 18/29 [00:46<00:29,  2.68s/it]\u001b[A\n",
            "Zamiana słów (próbka 98):  66% 19/29 [00:49<00:27,  2.71s/it]\u001b[A\n",
            "Zamiana słów (próbka 98):  69% 20/29 [00:52<00:24,  2.70s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.53it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  72% 21/29 [00:54<00:19,  2.42s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 153.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.95it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  76% 22/29 [00:56<00:17,  2.50s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.22it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  79% 23/29 [00:58<00:12,  2.14s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.78it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  83% 24/29 [01:00<00:10,  2.15s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 144.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 150.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.37it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  86% 25/29 [01:01<00:08,  2.02s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 186.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 145.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 151.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.67it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  90% 26/29 [01:04<00:06,  2.06s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.40it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  93% 27/29 [01:07<00:04,  2.46s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.38it/s]\n",
            "\n",
            "Zamiana słów (próbka 98):  97% 28/29 [01:09<00:02,  2.27s/it]\u001b[A\n",
            "Zamiana słów (próbka 98): 100% 29/29 [01:11<00:00,  2.32s/it]\u001b[A\n",
            "Przetwarzanie RAFT:  97% 98/101 [2:00:48<03:13, 64.42s/it]\n",
            "Zamiana słów (próbka 99):   0% 0/42 [00:00<?, ?it/s]\u001b[A\n",
            "Zamiana słów (próbka 99):   2% 1/42 [00:01<01:15,  1.84s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):   5% 2/42 [00:05<01:47,  2.69s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.98it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):   7% 3/42 [00:06<01:26,  2.21s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  10% 4/42 [00:09<01:35,  2.53s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.93it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  12% 5/42 [00:13<01:45,  2.85s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  14% 6/42 [00:16<01:47,  3.00s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 128.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 135.78it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  17% 7/42 [00:19<01:49,  3.13s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.45it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  19% 8/42 [00:21<01:34,  2.78s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.75it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  21% 9/42 [00:25<01:37,  2.96s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.47it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  24% 10/42 [00:28<01:34,  2.96s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.03it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  26% 11/42 [00:29<01:19,  2.57s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.00it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  29% 12/42 [00:32<01:14,  2.47s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.09it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  31% 13/42 [00:35<01:16,  2.64s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 171.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 183.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 177.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.65it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  33% 14/42 [00:37<01:07,  2.41s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  36% 15/42 [00:40<01:12,  2.68s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.76it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  38% 16/42 [00:41<01:00,  2.31s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 184.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 128.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 131.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.56it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  40% 17/42 [00:44<01:01,  2.48s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.60it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  43% 18/42 [00:46<00:52,  2.19s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  45% 19/42 [00:49<00:58,  2.53s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 129.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 132.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.59it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  48% 20/42 [00:51<00:51,  2.33s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  50% 21/42 [00:54<00:54,  2.59s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 125.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 136.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.59it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  52% 22/42 [00:56<00:47,  2.40s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  55% 23/42 [00:59<00:50,  2.64s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.65it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  57% 24/42 [01:03<00:51,  2.84s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 219.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.33it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  60% 25/42 [01:05<00:45,  2.68s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  62% 26/42 [01:08<00:46,  2.88s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 130.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 136.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 217.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.28it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  64% 27/42 [01:10<00:39,  2.64s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.02it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  67% 28/42 [01:14<00:39,  2.85s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 181.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 127.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 133.57it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  69% 29/42 [01:17<00:39,  3.01s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.60it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  71% 30/42 [01:20<00:37,  3.11s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  74% 31/42 [01:23<00:34,  3.10s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  76% 32/42 [01:27<00:31,  3.15s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 189.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 190.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 189.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.97it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  79% 33/42 [01:28<00:24,  2.74s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 189.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 126.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 131.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 177.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 125.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 129.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 186.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 126.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 131.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.42it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  81% 34/42 [01:31<00:20,  2.57s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 182.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 126.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 131.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 183.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 123.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 125.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 179.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.46it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  83% 35/42 [01:33<00:17,  2.54s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  86% 36/42 [01:36<00:15,  2.66s/it]\u001b[A\n",
            "Zamiana słów (próbka 99):  88% 37/42 [01:39<00:13,  2.60s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.05it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  90% 38/42 [01:40<00:09,  2.31s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 127.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 133.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 132.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 130.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 132.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 129.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 132.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 138.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 134.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 138.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 131.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.60it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  93% 39/42 [01:42<00:06,  2.28s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.51it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  95% 40/42 [01:46<00:05,  2.63s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 187.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 189.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.82it/s]\n",
            "\n",
            "Zamiana słów (próbka 99):  98% 41/42 [01:48<00:02,  2.41s/it]\u001b[A\n",
            "Zamiana słów (próbka 99): 100% 42/42 [01:51<00:00,  2.64s/it]\u001b[A\n",
            "Przetwarzanie RAFT:  98% 99/101 [2:02:49<02:42, 81.46s/it]\n",
            "Zamiana słów (próbka 100):   0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 153.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.40it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):   4% 1/26 [00:01<00:36,  1.48s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.71it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):   8% 2/26 [00:04<00:51,  2.14s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.39it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  12% 3/26 [00:06<00:56,  2.45s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.96it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  15% 4/26 [00:09<00:51,  2.32s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.11it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.72it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  19% 5/26 [00:11<00:48,  2.33s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.63it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.96it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  23% 6/26 [00:13<00:47,  2.39s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 152.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 191.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.35it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  27% 7/26 [00:15<00:40,  2.11s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.52it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  31% 8/26 [00:17<00:35,  1.98s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.52it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  35% 9/26 [00:18<00:30,  1.79s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 188.74it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.61it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  38% 10/26 [00:21<00:36,  2.25s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.19it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  42% 11/26 [00:25<00:38,  2.58s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.81it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  46% 12/26 [00:27<00:34,  2.45s/it]\u001b[A\n",
            "Zamiana słów (próbka 100):  50% 13/26 [00:29<00:31,  2.42s/it]\u001b[A\n",
            "Zamiana słów (próbka 100):  54% 14/26 [00:32<00:31,  2.66s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 183.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.59it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  58% 15/26 [00:34<00:26,  2.40s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 137.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 147.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 143.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 148.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.78it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.52it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  62% 16/26 [00:36<00:22,  2.30s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.75it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  65% 17/26 [00:39<00:23,  2.59s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.22it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  69% 18/26 [00:42<00:21,  2.66s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 184.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.45it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  73% 19/26 [00:46<00:19,  2.85s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.42it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  77% 20/26 [00:48<00:16,  2.69s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 192.76it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.44it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.56it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  81% 21/26 [00:50<00:12,  2.47s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.40it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  85% 22/26 [00:53<00:10,  2.72s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.95it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.48it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  88% 23/26 [00:55<00:07,  2.49s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.04it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.50it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  92% 24/26 [00:57<00:04,  2.24s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 181.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.02it/s]\n",
            "\n",
            "Zamiana słów (próbka 100):  96% 25/26 [01:00<00:02,  2.56s/it]\u001b[A\n",
            "Zamiana słów (próbka 100): 100% 26/26 [01:02<00:00,  2.51s/it]\u001b[A\n",
            "Przetwarzanie RAFT:  99% 100/101 [2:03:56<01:17, 77.31s/it]\n",
            "Zamiana słów (próbka 101):   0% 0/22 [00:00<?, ?it/s]\u001b[A\n",
            "Zamiana słów (próbka 101):   5% 1/22 [00:02<01:00,  2.87s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 194.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.59it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.76it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):   9% 2/22 [00:04<00:39,  1.97s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.71it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.16it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.80it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.35it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  14% 3/22 [00:07<00:45,  2.37s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 155.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 203.84it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 154.49it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.85it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  18% 4/22 [00:09<00:40,  2.24s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.34it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  23% 5/22 [00:12<00:44,  2.61s/it]\u001b[A\n",
            "Zamiana słów (próbka 101):  27% 6/22 [00:15<00:45,  2.82s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 193.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.90it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  32% 7/22 [00:17<00:36,  2.45s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.48it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.64it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.21it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  36% 8/22 [00:20<00:38,  2.75s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.28it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.99it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.55it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  41% 9/22 [00:22<00:31,  2.43s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 199.91it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.74it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  45% 10/22 [00:25<00:32,  2.68s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.53it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.69it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.96it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.05it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.01it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  50% 11/22 [00:29<00:31,  2.89s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.02it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.67it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 219.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 219.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 218.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.37it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  55% 12/22 [00:31<00:26,  2.70s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.89it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.32it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 202.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.81it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.71it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  59% 13/22 [00:32<00:20,  2.30s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 198.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.45it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.60it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 204.18it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  64% 14/22 [00:34<00:17,  2.14s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 185.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.50it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.62it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.29it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 154.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 158.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.18it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.61it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.82it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 157.83it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 159.17it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  68% 15/22 [00:36<00:14,  2.04s/it]\u001b[A\n",
            "Zamiana słów (próbka 101):  73% 16/22 [00:39<00:13,  2.28s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.70it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.98it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.86it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.35it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.73it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.24it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.37it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.42it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.41it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.77it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.01it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.08it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  77% 17/22 [00:40<00:10,  2.14s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 177.56it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.55it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.39it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 201.23it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.58it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.00it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.17it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.27it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 216.94it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 197.03it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.12it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  82% 18/22 [00:42<00:08,  2.02s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.13it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.36it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.68it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.75it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.38it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.40it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.07it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.97it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.79it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.52it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.25it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.14it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.06it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.31it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  86% 19/22 [00:44<00:05,  1.96s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 195.65it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.10it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.46it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.31it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 213.93it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.88it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 200.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.34it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 205.47it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.19it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.66it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.72it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.80it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  91% 20/22 [00:46<00:03,  1.86s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.09it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.15it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.54it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.08it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.30it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 207.12it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.90it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 208.85it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.57it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.22it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.51it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 210.26it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.21it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 214.87it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 212.92it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 215.43it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 211.33it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 209.29it/s]\n",
            "\n",
            "Zamiana słów (próbka 101):  95% 21/22 [00:48<00:01,  1.94s/it]\u001b[A\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 196.20it/s]\n",
            "\n",
            "\n",
            "Batches: 100% 1/1 [00:00<00:00, 206.03it/s]\n",
            "\n",
            "Zamiana słów (próbka 101): 100% 22/22 [00:51<00:00,  2.34s/it]\u001b[A\n",
            "Przetwarzanie RAFT: 100% 101/101 [2:04:51<00:00, 74.18s/it]\n",
            "Logger closed.\n",
            "\n",
            "--- Zakończono działanie skryptu RAFT dla abstracts_long.jsonl ---\n",
            "INFO: Wyniki powinny być zapisane w podkatalogu ./experiments/.\n"
          ]
        }
      ],
      "source": [
        "# Komórka Pythona do uruchomienia eksperymentu RAFT\n",
        "import os\n",
        "\n",
        "# --- KONFIGURACJA ---\n",
        "raft_dir = \"/content/drive/MyDrive/raft\"\n",
        "input_filename = \"abstracts_long.jsonl\" # <-- ZMIEŃ NA ŻĄDANY PLIK\n",
        "# --------------------\n",
        "\n",
        "# Sprawdź, czy jesteś w katalogu RAFT\n",
        "if os.getcwd() != raft_dir:\n",
        "  %cd {raft_dir}\n",
        "print(f\"\\nINFO: Katalog roboczy: {os.getcwd()}\")\n",
        "\n",
        "# Sprawdzenie, czy plik wejściowy istnieje\n",
        "raft_input_path = os.path.join(raft_dir, \"datasets\", \"custom_input\", \"test.jsonl\")\n",
        "if not os.path.exists(raft_input_path):\n",
        "     print(f\"BŁĄD: Plik wejściowy {raft_input_path} nie istnieje!\")\n",
        "else:\n",
        "    print(f\"Uruchamianie RAFT dla pliku: {input_filename}...\")\n",
        "    # Uruchomienie eksperymentu RAFT jako komendy powłoki (!)\n",
        "    !python experiment.py \\\n",
        "        --dataset custom_input \\\n",
        "        --mask_pct 0.1 \\\n",
        "        --top_k 10 \\\n",
        "        --proxy_model gpt-j-6b \\\n",
        "        --detector roberta-large \\\n",
        "        --candidate_generation local_llm \\\n",
        "        --local_llm_model_id mistralai/Mistral-7B-Instruct-v0.1 \\\n",
        "        --dataset_dir ./datasets \\\n",
        "        --proxy_model_device cuda \\\n",
        "        --target_detector_device cuda \\\n",
        "        --output_path ./experiments/ \\\n",
        "\n",
        "    print(f\"\\n--- Zakończono działanie skryptu RAFT dla {input_filename} ---\")\n",
        "    print(\"INFO: Wyniki powinny być zapisane w podkatalogu ./experiments/.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/raft/datasets/custom_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9qowfdckZCG",
        "outputId": "faa43241-1504-4935-dd51-264adf7581b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abstracts_long.jsonl   creative_long.jsonl   essays_long.jsonl\t test.jsonl\n",
            "abstracts_short.jsonl  creative_short.jsonl  essays_short.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Results"
      ],
      "metadata": {
        "id": "Sg1euknJ0Bur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIAc4EIedqL",
        "outputId": "37ad9a5e-3233-4f77-e8a4-02db51b0f6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"original\": \"Preheat the oven to 350 degrees and place the cookie dough in the microwave. Roll out the dough into a 1-inch circle, about 2 inches from the center of the dough. Cut the cookies into 5-inch squares. Using a fork, slice each cookie into 1/2 inch cubes. Brush one cookie with the butter mixture; set aside. Mix together the cream cheese and sugar until well blended. Stir in the flour and salt. Spoon the melted butter over each cookie. Roll out two pieces of dough onto the cookie sheet. Place them on a lightly floured surface and fold down half way. Remove the cookie sheets when the edges are fully folded up so that they will not slide or slip off the cookie sheet during baking. Bake for 8 minutes or until golden brown and lightly oiled. Let cool completely before cutting into slices. Paste the cookies onto a greased 9×13 baking pan. When you see red circles around the edges of each piece, remove the pans from the oven immediately and cut through\",\n",
            "    \"sampled\": \"Preheat the oven to 350 degrees and place the cookie dough in the microwave. Roll out the dough into a 1-inch circle, about 2 inches from the center of the dough. Cut the cookies into inch squares. Using a fork, cut each cookie into 1/2 inch cubes. Brush one cookie with the butter mixture; set aside. Mix together the cream cheese and sugar until well blended. Stir in the flour and salt. Spoon the melted butter over each cookie. Roll out two pieces of dough onto the cookie sheet. Place them on a lightly floured surface and fold down portion way. Remove the cookie sheets when the edges are completely folded up so that they will not slide or slip off the cookie sheet during baking. Bake for 8 minutes or until golden brown and lightly oiled. Let cool completely before cutting into slices. Paste the cookies onto a greased 9×13 baking pan. When you see purple circles around the edges of each piece, remove the pans from the oven promptly and cut through\",\n",
            "    \"replacement_keys\": [\n",
            "        35,\n",
            "        40,\n",
            "        99,\n",
            "        109,\n",
            "        156,\n",
            "        170\n",
            "    ],\n",
            "    \"original_crit\": 0.9379201531410217,\n",
            "    \"sampled_crit\": 0.8709778189659119,\n",
            "    \"original_llm_likelihood\": 0.9379201531410217,\n",
            "    \"sampled_llm_likelihood\": 0.8709778189659119\n",
            "}\n",
            "----------------------------------------\n",
            "Indeks 35: Original -> 5-inch, Sampled -> inch\n",
            "Indeks 40: Original -> slice, Sampled -> cut\n",
            "Indeks 99: Original -> half, Sampled -> portion\n",
            "Indeks 109: Original -> fully, Sampled -> completely\n",
            "Indeks 156: Original -> red, Sampled -> purple\n",
            "Indeks 170: Original -> immediately, Sampled -> promptly\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import json\n",
        "\n",
        "# Wyszukujemy plik (folder zaczynający się od 'custom_input')\n",
        "files = glob.glob('/content/drive/MyDrive/raft/experiments/custom_input*/result_0.json')\n",
        "if not files:\n",
        "    print(\"Nie znaleziono pliku!\")\n",
        "else:\n",
        "    file_path = files[0]  # bierzemy pierwszy znaleziony plik\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Wyświetlamy całą zawartość pliku\n",
        "    print(json.dumps(data, indent=4, ensure_ascii=False))\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Rozdzielamy teksty na słowa (domyślnie przy użyciu spacji)\n",
        "    original_words = data['original'].split()\n",
        "    sampled_words = data['sampled'].split()\n",
        "    replacement_keys = data['replacement_keys']\n",
        "\n",
        "    # Sprawdzamy i wyświetlamy słowa znajdujące się na podanych indeksach\n",
        "    for idx in replacement_keys:\n",
        "        # Upewniamy się, że indeks mieści się w zakresie listy słów\n",
        "        orig_word = original_words[idx] if idx < len(original_words) else \"[brak słowa]\"\n",
        "        samp_word = sampled_words[idx] if idx < len(sampled_words) else \"[brak słowa]\"\n",
        "        print(f\"Indeks {idx}: Original -> {orig_word}, Sampled -> {samp_word}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o30Nq4ozcWB"
      },
      "source": [
        "#SICO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyNqwN30zYNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52db72a6-d045-4b12-f44e-474ab41ba958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SICO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPunyknMHpUE",
        "outputId": "f0d514ed-ab6d-4953-a99f-4d7f46983932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SICO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Environment and requirenments"
      ],
      "metadata": {
        "id": "hp2CHREayqA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLBAbwIxyOfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50963a6d-b3cc-4e5b-f137-f7379dfef393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py38h06a4308_2\n",
            "    - cffi==1.15.0=py38hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py38h7f8727e_0\n",
            "    - conda==4.12.0=py38h06a4308_0\n",
            "    - cryptography==36.0.0=py38h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.13=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py38h27cfd23_0\n",
            "    - setuptools==61.2.0=py38h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py38h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py38hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py38h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py38h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py38h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.13-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py38h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py38h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "conda 4.12.0\n",
            "/content/drive/MyDrive/SICO\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| WARNING conda.models.version:get_matcher(535): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\n",
            "WARNING conda.models.version:get_matcher(535): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\n",
            "WARNING conda.models.version:get_matcher(535): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\n",
            "WARNING conda.models.version:get_matcher(535): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pip-23.0.1           | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.15it/s]\n",
            "c-ares-1.18.1        | 114 KB    | : 100% 1.0/1 [00:00<00:00,  2.97it/s]\n",
            "libsodium-1.0.18     | 366 KB    | : 100% 1.0/1 [00:00<00:00, 10.50it/s]\n",
            "mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [00:03<00:00,  3.53s/it]               \n",
            "aiohttp-3.8.1        | 574 KB    | : 100% 1.0/1 [00:00<00:00,  5.83it/s]\n",
            "stack_data-0.6.2     | 26 KB     | : 100% 1.0/1 [00:00<00:00,  3.14it/s]\n",
            "cuda-version-12.8    | 17 KB     | : 100% 1.0/1 [00:00<00:00,  3.14it/s]\n",
            "lz4-c-1.9.4          | 154 KB    | : 100% 1.0/1 [00:00<00:00,  3.11it/s]\n",
            "xxhash-0.8.0         | 86 KB     | : 100% 1.0/1 [00:00<00:00, 17.02it/s]\n",
            "abseil-cpp-20211102. | 1020 KB   | : 100% 1.0/1 [00:00<00:00,  2.70it/s]\n",
            "libnvjpeg-11.9.0.86  | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\n",
            "libbrotlidec-1.0.9   | 31 KB     | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "libbrotlienc-1.0.9   | 264 KB    | : 100% 1.0/1 [00:00<00:00,  3.26it/s]\n",
            "psutil-5.9.0         | 330 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "backports.functools_ | 9 KB      | : 100% 1.0/1 [00:00<00:00,  9.81it/s]\n",
            "unicodedata2-14.0.0  | 498 KB    | : 100% 1.0/1 [00:00<00:00,  9.48it/s]\n",
            "libwebp-1.2.4        | 79 KB     | : 100% 1.0/1 [00:00<00:00,  3.24it/s]\n",
            "pyparsing-3.0.9      | 152 KB    | : 100% 1.0/1 [00:00<00:00,  3.18it/s]\n",
            "libiconv-1.16        | 736 KB    | : 100% 1.0/1 [00:00<00:00,  2.97it/s]\n",
            "termcolor-2.2.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "requests-2.28.2      | 55 KB     | : 100% 1.0/1 [00:00<00:00,  2.89it/s]\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00,  3.24it/s]\n",
            "libev-4.33           | 111 KB    | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "pyarrow-8.0.0        | 2.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.63it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "zstd-1.5.2           | 488 KB    | : 100% 1.0/1 [00:00<00:00,  3.21it/s]\n",
            "zlib-1.2.13          | 103 KB    | : 100% 1.0/1 [00:00<00:00,  3.21it/s]\n",
            "cuda-nvtx-11.8.86    | 57 KB     | : 100% 1.0/1 [00:00<00:00, 19.82it/s]\n",
            "snappy-1.1.9         | 636 KB    | : 100% 1.0/1 [00:00<00:00,  1.26it/s]             \n",
            "kiwisolver-1.4.4     | 76 KB     | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "jedi-0.18.2          | 786 KB    | : 100% 1.0/1 [00:00<00:00,  1.99it/s]\n",
            "yarl-1.7.2           | 133 KB    | : 100% 1.0/1 [00:00<00:00, 13.81it/s]\n",
            "python-dateutil-2.8. | 233 KB    | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "freetype-2.12.1      | 626 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "backports-1.0        | 6 KB      | : 100% 1.0/1 [00:00<00:00,  3.09it/s]\n",
            "wheel-0.38.4         | 63 KB     | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\n",
            "nest-asyncio-1.5.6   | 10 KB     | : 100% 1.0/1 [00:00<00:00, 18.80it/s]\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:03<00:00,  3.12s/it]\n",
            "pyzmq-19.0.2         | 511 KB    | : 100% 1.0/1 [00:00<00:00,  6.24it/s]\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:19<00:00, 19.11s/it]               \n",
            "libffi-3.4.2         | 136 KB    | : 100% 1.0/1 [00:00<00:00,  2.90it/s]\n",
            "nltk-3.7             | 1010 KB   | : 100% 1.0/1 [00:00<00:00,  2.78it/s]\n",
            "backcall-0.2.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 21.36it/s]\n",
            "pickleshare-0.7.5    | 9 KB      | : 100% 1.0/1 [00:00<00:00, 25.01it/s]\n",
            "fsspec-2023.3.0      | 109 KB    | : 100% 1.0/1 [00:00<00:00,  3.13it/s]\n",
            "parso-0.8.3          | 69 KB     | : 100% 1.0/1 [00:00<00:00, 16.78it/s]\n",
            "setuptools-67.5.1    | 566 KB    | : 100% 1.0/1 [00:00<00:00,  2.90it/s]\n",
            "gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.05it/s]\n",
            "libtiff-4.5.0        | 524 KB    | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\n",
            "mkl_random-1.2.2     | 308 KB    | : 100% 1.0/1 [00:00<00:00,  3.05it/s]\n",
            "python-xxhash-2.0.2  | 21 KB     | : 100% 1.0/1 [00:00<00:00,  3.33it/s]\n",
            "click-8.0.4          | 151 KB    | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "libtasn1-4.16.0      | 58 KB     | : 100% 1.0/1 [00:00<00:00,  3.35it/s]\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [00:22<00:00, 22.55s/it]               \n",
            "mkl-service-2.4.0    | 59 KB     | : 100% 1.0/1 [00:00<00:00,  3.29it/s]\n",
            "networkx-3.1         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.46it/s]\n",
            "libdeflate-1.8       | 51 KB     | : 100% 1.0/1 [00:00<00:00,  3.36it/s]\n",
            "tk-8.6.12            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\n",
            "aws-c-event-stream-0 | 25 KB     | : 100% 1.0/1 [00:00<00:00,  2.51it/s]\n",
            "pyyaml-6.0           | 189 KB    | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\n",
            "libbrotlicommon-1.0. | 70 KB     | : 100% 1.0/1 [00:00<00:00,  3.31it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]\n",
            "ca-certificates-2022 | 143 KB    | : 100% 1.0/1 [00:00<00:00,  3.10it/s]\n",
            "giflib-5.2.1         | 79 KB     | : 100% 1.0/1 [00:00<00:00,  3.29it/s]\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [00:19<00:00, 19.73s/it]               \n",
            "libjpeg-turbo-2.0.0  | 950 KB    | : 100% 1.0/1 [00:00<00:00,  5.07it/s]\n",
            "xz-5.2.10            | 429 KB    | : 100% 1.0/1 [00:00<00:00,  2.94it/s]\n",
            "grpc-cpp-1.46.1      | 4.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.54it/s]\n",
            "multidict-6.0.2      | 52 KB     | : 100% 1.0/1 [00:00<00:00, 19.27it/s]\n",
            "ptyprocess-0.7.0     | 16 KB     | : 100% 1.0/1 [00:00<00:00, 24.18it/s]\n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00,  3.32it/s]\n",
            "charset-normalizer-2 | 36 KB     | : 100% 1.0/1 [00:00<00:00, 22.33it/s]\n",
            "lame-3.100           | 323 KB    | : 100% 1.0/1 [00:00<00:00,  3.22it/s]\n",
            "debugpy-1.5.1        | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\n",
            "frozenlist-1.3.3     | 45 KB     | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "libcufile-1.13.1.3   | 936 KB    | : 100% 1.0/1 [00:00<00:00,  3.02it/s]\n",
            "re2-2022.04.01       | 210 KB    | : 100% 1.0/1 [00:00<00:00,  3.35it/s]\n",
            "libnghttp2-1.46.0    | 680 KB    | : 100% 1.0/1 [00:00<00:00,  1.51it/s]\n",
            "libcurl-7.87.0       | 373 KB    | : 100% 1.0/1 [00:00<00:00,  3.26it/s]\n",
            "importlib_resources- | 32 KB     | : 100% 1.0/1 [00:00<00:00,  2.87it/s]\n",
            "packaging-23.0       | 40 KB     | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n",
            "intel-openmp-2021.4. | 4.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.47it/s]\n",
            "numexpr-2.8.4        | 134 KB    | : 100% 1.0/1 [00:00<00:00,  3.24it/s]\n",
            "numpy-1.22.3         | 6.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "krb5-1.19.4          | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.01it/s]\n",
            "libunistring-0.9.10  | 536 KB    | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "sympy-1.13.3         | 4.4 MB    | : 100% 1.0/1 [00:00<00:00,  1.87it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  1.76it/s]\n",
            "llvm-openmp-12.0.1   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.21it/s]\n",
            "pexpect-4.8.0        | 48 KB     | : 100% 1.0/1 [00:00<00:00, 22.78it/s]\n",
            "libevent-2.1.12      | 425 KB    | : 100% 1.0/1 [00:00<00:00,  3.18it/s]\n",
            "matplotlib-inline-0. | 12 KB     | : 100% 1.0/1 [00:00<00:00, 20.62it/s]\n",
            "flit-core-3.6.0      | 42 KB     | : 100% 1.0/1 [00:00<00:00,  3.17it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  3.18it/s]\n",
            "python-3.8.16        | 23.7 MB   | : 100% 1.0/1 [00:00<00:00,  1.27it/s]               \n",
            "aws-checksums-0.1.9  | 49 KB     | : 100% 1.0/1 [00:00<00:00,  3.10it/s]\n",
            "utf8proc-2.6.1       | 308 KB    | : 100% 1.0/1 [00:00<00:00,  3.25it/s]\n",
            "multiprocess-0.70.14 | 238 KB    | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "pandas-1.4.2         | 12.6 MB   | : 100% 1.0/1 [00:02<00:00,  2.65s/it]               \n",
            "libwebp-base-1.2.4   | 347 KB    | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\n",
            "libcblas-3.9.0       | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.18it/s]\n",
            "lcms2-2.12           | 312 KB    | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "fire-0.4.0           | 79 KB     | : 100% 1.0/1 [00:00<00:00,  3.05it/s]                \n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "mpmath-1.3.0         | 428 KB    | : 100% 1.0/1 [00:00<00:00,  2.94it/s]\n",
            "arrow-cpp-8.0.0      | 10.6 MB   | : 100% 1.0/1 [00:00<00:00,  1.88it/s]\n",
            "cuda-libraries-11.8. | 1 KB      | : 100% 1.0/1 [00:00<00:00, 28.26it/s]\n",
            "regex-2022.4.24      | 375 KB    | : 100% 1.0/1 [00:00<00:00,  9.26it/s]\n",
            "jinja2-3.1.4         | 109 KB    | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\n",
            "gflags-2.2.2         | 126 KB    | : 100% 1.0/1 [00:00<00:00,  1.05it/s]\n",
            "markupsafe-2.1.1     | 22 KB     | : 100% 1.0/1 [00:00<00:00, 16.29it/s]\n",
            "bottleneck-1.3.5     | 115 KB    | : 100% 1.0/1 [00:00<00:00,  1.12it/s]\n",
            "orc-1.7.4            | 972 KB    | : 100% 1.0/1 [00:00<00:00,  3.11it/s]\n",
            "pillow-9.3.0         | 728 KB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]\n",
            "traitlets-5.9.0      | 96 KB     | : 100% 1.0/1 [00:00<00:00,  3.05it/s]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | : 100% 1.0/1 [00:48<00:00, 48.44s/it]               \n",
            "async-timeout-4.0.2  | 11 KB     | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "tornado-6.1          | 645 KB    | : 100% 1.0/1 [00:00<00:00,  4.68it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.47it/s]\n",
            "pytorch-2.4.1        | 1.53 GB   | : 100% 1.0/1 [03:31<00:00, 211.72s/it]             \n",
            "typing_extensions-4. | 46 KB     | : 100% 1.0/1 [00:00<00:00,  1.50it/s]\n",
            "prompt-toolkit-3.0.3 | 265 KB    | : 100% 1.0/1 [00:00<00:00,  2.73it/s]\n",
            "torchaudio-2.4.1     | 6.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.02it/s]\n",
            "joblib-1.2.0         | 205 KB    | : 100% 1.0/1 [00:00<00:00,  6.35it/s]               \n",
            "seaborn-0.12.2       | 491 KB    | : 100% 1.0/1 [00:00<00:00,  3.14it/s]\n",
            "dataclasses-0.8      | 10 KB     | : 100% 1.0/1 [00:00<00:00, 20.72it/s]\n",
            "dill-0.3.6           | 167 KB    | : 100% 1.0/1 [00:00<00:00,  1.09it/s]\n",
            "mkl_fft-1.3.1        | 180 KB    | : 100% 1.0/1 [00:00<00:00,  3.24it/s]\n",
            "pytorch-mutex-1.0    | 3 KB      | : 100% 1.0/1 [00:00<00:00, 26.21it/s]\n",
            "brotli-1.0.9         | 18 KB     | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\n",
            "filelock-3.9.0       | 18 KB     | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\n",
            "pytorch-cuda-11.8    | 7 KB      | : 100% 1.0/1 [00:00<00:00, 25.17it/s]\n",
            "typing-extensions-4. | 8 KB      | : 100% 1.0/1 [00:00<00:00,  3.27it/s]\n",
            "libedit-3.1.20221030 | 181 KB    | : 100% 1.0/1 [00:01<00:00,  1.63s/it]\n",
            "pytz-2022.7.1        | 182 KB    | : 100% 1.0/1 [00:00<00:00,  1.11it/s]\n",
            "entrypoints-0.4      | 9 KB      | : 100% 1.0/1 [00:00<00:00, 25.63it/s]\n",
            "idna-3.4             | 93 KB     | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\n",
            "importlib-metadata-6 | 24 KB     | : 100% 1.0/1 [00:00<00:00,  3.19it/s]\n",
            "matplotlib-base-3.7. | 6.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]\n",
            "libblas-3.9.0        | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.12it/s]\n",
            "pygments-2.14.0      | 805 KB    | : 100% 1.0/1 [00:00<00:00,  2.19it/s]\n",
            "liblapack-3.9.0      | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\n",
            "aiosignal-1.3.1      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 16.91it/s]\n",
            "gmp-6.2.1            | 544 KB    | : 100% 1.0/1 [00:00<00:00,  3.12it/s]\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [00:04<00:00,  4.02s/it]\n",
            "pure_eval-0.2.2      | 14 KB     | : 100% 1.0/1 [00:00<00:00, 23.77it/s]\n",
            "libthrift-0.15.0     | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.64it/s]\n",
            "fonttools-4.33.3     | 1.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.55it/s]\n",
            "lerc-3.0             | 196 KB    | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "decorator-5.1.1      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 25.22it/s]\n",
            "contourpy-1.0.2      | 224 KB    | : 100% 1.0/1 [00:00<00:00, 13.45it/s]\n",
            "brotli-bin-1.0.9     | 19 KB     | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "libssh2-1.10.0       | 274 KB    | : 100% 1.0/1 [00:01<00:00,  1.06s/it]\n",
            "zeromq-4.3.4         | 351 KB    | : 100% 1.0/1 [00:00<00:00,  9.06it/s]\n",
            "ipython-8.10.0       | 560 KB    | : 100% 1.0/1 [00:00<00:00,  2.81it/s]\n",
            "tqdm-4.64.1          | 125 KB    | : 100% 1.0/1 [00:00<00:00,  1.28it/s]\n",
            "glog-0.5.0           | 101 KB    | : 100% 1.0/1 [00:00<00:00,  3.26it/s]\n",
            "libcurand-10.3.9.90  | 43.5 MB   | : 100% 1.0/1 [00:00<00:00,  1.11it/s]               \n",
            "libboost-1.73.0      | 13.8 MB   | : 100% 1.0/1 [00:01<00:00,  1.86s/it]               \n",
            "torchvision-0.20.0   | 13.2 MB   | : 100% 1.0/1 [00:01<00:00,  2.00s/it]               \n",
            "importlib_metadata-6 | 9 KB      | : 100% 1.0/1 [00:00<00:00,  3.14it/s]\n",
            "nettle-3.7.3         | 809 KB    | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\n",
            "cuda-cudart-11.8.89  | 197 KB    | : 100% 1.0/1 [00:00<00:00, 15.50it/s]\n",
            "blas-1.0             | 1 KB      | : 100% 1.0/1 [00:00<00:00, 29.10it/s]\n",
            "urllib3-1.26.14      | 196 KB    | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n",
            "tokenizers-0.13.2    | 4.5 MB    | : 100% 1.0/1 [00:12<00:00, 12.01s/it]\n",
            "aws-c-common-0.4.57  | 156 KB    | : 100% 1.0/1 [00:00<00:00,  3.20it/s]\n",
            "openssl-1.1.1t       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.73it/s]\n",
            "executing-1.2.0      | 24 KB     | : 100% 1.0/1 [00:00<00:00, 17.27it/s]\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [00:18<00:00, 18.37s/it]               \n",
            "cffi-1.15.1          | 241 KB    | : 100% 1.0/1 [00:00<00:00,  3.22it/s]\n",
            "wcwidth-0.2.6        | 28 KB     | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n",
            "jupyter_core-5.2.0   | 89 KB     | : 100% 1.0/1 [00:00<00:00,  2.38it/s]\n",
            "sqlite-3.40.1        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.24it/s]               \n",
            "ipykernel-6.15.0     | 96 KB     | : 100% 1.0/1 [00:00<00:00, 15.05it/s]\n",
            "platformdirs-3.0.0   | 17 KB     | : 100% 1.0/1 [00:00<00:00,  3.03it/s]\n",
            "libprotobuf-3.20.3   | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.84it/s]\n",
            "python_abi-3.8       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 24.10it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.40it/s]\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]               \n",
            "cycler-0.11.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00,  3.33it/s]\n",
            "aws-sdk-cpp-1.8.185  | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  2.29it/s]\n",
            "openh264-2.1.1       | 711 KB    | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n",
            "_libgcc_mutex-0.1    | 2 KB      | : 100% 1.0/1 [00:00<00:00,  5.62it/s]\n",
            "jpeg-9e              | 240 KB    | : 100% 1.0/1 [00:00<00:00,  3.16it/s]\n",
            "certifi-2022.12.7    | 147 KB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]\n",
            "attrs-22.2.0         | 53 KB     | : 100% 1.0/1 [00:00<00:00,  3.07it/s]\n",
            "torchtriton-3.0.0    | 233.4 MB  | : 100% 1.0/1 [00:33<00:00, 33.16s/it]               \n",
            "cryptography-38.0.4  | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.79it/s]\n",
            "munkres-1.1.4        | 13 KB     | : 100% 1.0/1 [00:00<00:00,  3.24it/s]\n",
            "asttokens-2.2.1      | 27 KB     | : 100% 1.0/1 [00:00<00:00,  3.08it/s]\n",
            "cuda-runtime-11.8.0  | 1 KB      | : 100% 1.0/1 [00:00<00:00, 12.82it/s]\n",
            "jupyter_client-7.0.6 | 87 KB     | : 100% 1.0/1 [00:00<00:00, 16.17it/s]\n",
            "libidn2-2.3.2        | 81 KB     | : 100% 1.0/1 [00:00<00:00,  2.19it/s]\n",
            "zipp-3.14.0          | 17 KB     | : 100% 1.0/1 [00:00<00:00,  1.71it/s]               \n",
            "boost-cpp-1.73.0     | 16 KB     | : 100% 1.0/1 [00:00<00:00,  3.25it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/chatgpt/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting accelerate==0.16.0\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 16.2 MB/s eta 0:00:00\n",
            "Collecting aiofiles==23.1.0\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting altair==4.2.2\n",
            "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 813.6/813.6 kB 66.3 MB/s eta 0:00:00\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.4/112.4 kB 17.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting anyio==3.6.2\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 12.8 MB/s eta 0:00:00\n",
            "Collecting appdirs==1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting bitarray==2.7.3\n",
            "  Downloading bitarray-2.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (271 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 271.8/271.8 kB 28.0 MB/s eta 0:00:00\n",
            "Collecting colorama==0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting cython==0.29.33\n",
            "  Downloading Cython-0.29.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 85.6 MB/s eta 0:00:00\n",
            "Collecting datasets==2.12.0\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 52.8 MB/s eta 0:00:00\n",
            "Collecting docker-pycreds==0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting docopt==0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting fairscale==0.4.13\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 35.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting fairseq==0.12.2\n",
            "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 102.9 MB/s eta 0:00:00\n",
            "Collecting fastapi==0.95.1\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 8.1 MB/s eta 0:00:00\n",
            "Collecting ffmpy==0.3.0\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting fuzzywuzzy==0.18.0\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting gitdb==4.0.10\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 10.1 MB/s eta 0:00:00\n",
            "Collecting gitpython==3.1.31\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 26.8 MB/s eta 0:00:00\n",
            "Collecting gradio==3.23.0\n",
            "  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.8/15.8 MB 87.8 MB/s eta 0:00:00\n",
            "Collecting h11==0.14.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 8.8 MB/s eta 0:00:00\n",
            "Collecting httpcore==0.17.0\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.6/70.6 kB 8.3 MB/s eta 0:00:00\n",
            "Collecting httpx==0.24.0\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.3/75.3 kB 11.7 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub==0.13.4\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.1/200.1 kB 23.0 MB/s eta 0:00:00\n",
            "Collecting hydra-core==1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.8/123.8 kB 20.3 MB/s eta 0:00:00\n",
            "Collecting importlib-resources==5.12.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting jinja2==3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 18.2 MB/s eta 0:00:00\n",
            "Collecting jsonschema==4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 13.7 MB/s eta 0:00:00\n",
            "Collecting language-tool-python==2.7.1\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting lemminflect==0.2.3\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.7/769.7 kB 69.3 MB/s eta 0:00:00\n",
            "Collecting levenshtein==0.20.9\n",
            "  Downloading Levenshtein-0.20.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 174.0/174.0 kB 27.0 MB/s eta 0:00:00\n",
            "Collecting linkify-it-py==2.0.2\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting lxml==4.9.2\n",
            "  Downloading lxml-4.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.1/7.1 MB 115.1 MB/s eta 0:00:00\n",
            "Collecting markdown-it-py==2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 12.8 MB/s eta 0:00:00\n",
            "Collecting markdown2==2.4.8\n",
            "  Downloading markdown2-2.4.8-py2.py3-none-any.whl (38 kB)\n",
            "Collecting markupsafe==2.1.2\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mdit-py-plugins==0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 8.7 MB/s eta 0:00:00\n",
            "Collecting mdurl==0.1.2\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting nh3==0.2.11\n",
            "  Downloading nh3-0.2.11-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 86.3 MB/s eta 0:00:00\n",
            "Collecting omegaconf==2.0.5\n",
            "  Downloading omegaconf-2.0.5-py3-none-any.whl (36 kB)\n",
            "Collecting openai==0.27.1\n",
            "  Downloading openai-0.27.1.tar.gz (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.3/57.3 kB 8.0 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting openfile==0.0.7\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting orjson==3.8.12\n",
            "  Downloading orjson-3.8.12-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.2/137.2 kB 668.5 kB/s eta 0:00:00\n",
            "Collecting pathtools==0.1.2\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pkgutil-resolve-name==1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Collecting portalocker==2.7.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 76.9 MB/s eta 0:00:00\n",
            "Collecting py3nvml==0.2.7\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 8.1 MB/s eta 0:00:00\n",
            "Collecting pydantic==1.10.7\n",
            "  Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 107.5 MB/s eta 0:00:00\n",
            "Collecting pydub==0.25.1\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pyrsistent==0.19.3\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 8.7 MB/s eta 0:00:00\n",
            "Collecting python-levenshtein==0.20.9\n",
            "  Downloading python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting python-multipart==0.0.6\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.7/45.7 kB 6.9 MB/s eta 0:00:00\n",
            "Collecting rapidfuzz==2.13.7\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 26.1 MB/s eta 0:00:00\n",
            "Collecting responses==0.18.0\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting sacrebleu==2.3.1\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.9/118.9 kB 19.9 MB/s eta 0:00:00\n",
            "Collecting sacremoses==0.0.53\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 880.6/880.6 kB 74.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 121.0 MB/s eta 0:00:00\n",
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 52.3 MB/s eta 0:00:00\n",
            "Collecting semantic-version==2.10.0\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 14.5 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 78.3 MB/s eta 0:00:00\n",
            "Collecting sentry-sdk==1.16.0\n",
            "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 17.9 MB/s eta 0:00:00\n",
            "Collecting setproctitle==1.3.2\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting shortuuid==1.0.11\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting smmap==5.0.0\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting sniffio==1.3.0\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting starlette==0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.9/66.9 kB 8.6 MB/s eta 0:00:00\n",
            "Collecting svgwrite==1.4.3\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 9.3 MB/s eta 0:00:00\n",
            "Collecting tabulate==0.9.0\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting threadpoolctl==3.1.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting tiktoken==0.3.3\n",
            "  Downloading tiktoken-0.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 84.9 MB/s eta 0:00:00\n",
            "Collecting toolwrapper==2.1.0\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting toolz==0.12.0\n",
            "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 8.6 MB/s eta 0:00:00\n",
            "Collecting transformers==4.28.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 125.1 MB/s eta 0:00:00\n",
            "Collecting types-pyyaml==6.0.12.9\n",
            "  Downloading types_PyYAML-6.0.12.9-py3-none-any.whl (14 kB)\n",
            "Collecting uc-micro-py==1.0.2\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Collecting uctools==1.3.0\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting uvicorn==0.22.0\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 9.3 MB/s eta 0:00:00\n",
            "Collecting wandb==0.15.0\n",
            "  Downloading wandb-0.15.0-py3-none-any.whl (2.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 90.2 MB/s eta 0:00:00\n",
            "Collecting wavedrom==2.0.3.post3\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 20.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting websockets==11.0.3\n",
            "  Downloading websockets-11.0.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 16.1 MB/s eta 0:00:00\n",
            "Collecting xmltodict==0.13.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (1.22.3)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (5.9.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from altair==4.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from altair==4.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from anyio==3.6.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (8.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (0.3.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (2.28.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (3.8.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (2023.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (2.0.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from docker-pycreds==0.4.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from fairseq==0.12.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 14)) (2.4.1)\n",
            "Requirement already satisfied: cffi in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from fairseq==0.12.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 14)) (1.15.1)\n",
            "Requirement already satisfied: regex in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from fairseq==0.12.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 14)) (2022.4.24)\n",
            "Requirement already satisfied: matplotlib in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (9.3.0)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 14.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (4.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from httpcore==0.17.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 22)) (2022.12.7)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from huggingface-hub==0.13.4->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 24)) (3.9.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from importlib-resources==5.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 26)) (3.14.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from jsonschema==4.17.3->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 28)) (22.2.0)\n",
            "Requirement already satisfied: urllib3>=1.25.10 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from responses==0.18.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 55)) (1.26.14)\n",
            "Requirement already satisfied: click in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from sacremoses==0.0.53->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 57)) (8.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from sacremoses==0.0.53->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 57)) (1.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from sentence-transformers==2.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 61)) (0.20.0)\n",
            "Requirement already satisfied: nltk in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from sentence-transformers==2.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 61)) (3.7)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from transformers==4.28.1->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 75)) (0.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from wandb==0.15.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 80)) (67.5.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from aiohttp->datasets==2.12.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 10)) (2.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from pandas>=0.18->altair==4.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from pandas>=0.18->altair==4.2.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 3)) (2022.7.1)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.8/45.8 kB 6.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: sympy in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from torch>=1.4.0->accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from torch>=1.4.0->accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from cffi->fairseq==0.12.2->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 14)) (2.21)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from matplotlib->gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (1.0.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from matplotlib->gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (4.33.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from matplotlib->gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from matplotlib->gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from matplotlib->gradio==3.23.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 20)) (3.0.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/chatgpt/lib/python3.8/site-packages (from sympy->torch>=1.4.0->accelerate==0.16.0->-r /content/drive/MyDrive/SICO/condaenv.erq8jo32.requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, docopt, fairscale, ffmpy, openai, pathtools, sacremoses, sentence-transformers, toolwrapper, uctools, wavedrom\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=9a14cb4eb84c869de93703e6b2aa50457d302dedc66c03b72afd92640419734b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=00f9b5c7f67902f85cc9d462b980687cb9cfaa15ce5ac7c5f643e49e9ad593ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for fairscale (pyproject.toml): started\n",
            "  Building wheel for fairscale (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332106 sha256=c086ad31b4d1d344b26a97fbd0661f8bfab773cbe96fcd4c239e3ca0dfb68bc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/02/9b/dc7d4ff5145afdd28f456dae6605a46619af0370eca30d8d7e\n",
            "  Building wheel for ffmpy (setup.py): started\n",
            "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=766b255bfc9bb2b70074eceba3e729da486c0f0132c65ceb7c8ca03648352f21\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for openai (pyproject.toml): started\n",
            "  Building wheel for openai (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for openai: filename=openai-0.27.1-py3-none-any.whl size=70083 sha256=70cf4f3a15374330329a7dee0557c0f0771b9090daba3ffc0a42ea55c804ce92\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/0f/40/80d12fc510872db194d1890e383da7b9f7c5d26f2481db3a33\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=72756257a1ea0a09d2ab51d16223dff28e5603acbc26d10504560d65e262116c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=249dd9a14e1b7ce3f62e49195e5645d260888bfc34d45df872aa4f07fdb47bd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=0b25fbc375f52766d7fd20bfaaa36ff5483ad67bf9d0fae452e544532b8a5261\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "  Building wheel for toolwrapper (setup.py): started\n",
            "  Building wheel for toolwrapper (setup.py): finished with status 'done'\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3337 sha256=dd115201ee0d6b01499a4c23f779ecd55ef6c8ff911f8861c4b6ba9db4a1b8a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/b8/9a/8996bde8158351e5c4564eeb6672137b9be465cb1c674b1a8b\n",
            "  Building wheel for uctools (setup.py): started\n",
            "  Building wheel for uctools (setup.py): finished with status 'done'\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=15fd109905f4a421e753460be2cc78bbb38ee1f8632518a88c89010a65794dc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/4b/a5/df174aa13cc8afc6a8198372d57b967667e2e5b49a0b23e790\n",
            "  Building wheel for wavedrom (setup.py): started\n",
            "  Building wheel for wavedrom (setup.py): finished with status 'done'\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30082 sha256=9ef4af27cd5a5b888fed5ffbca072a8c4ee93b5e42f59d49379d2819a1216a8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/b2/21/5266400b4e65ab57862edfd078d2382696cec13ffe8fb171cb\n",
            "Successfully built antlr4-python3-runtime docopt fairscale ffmpy openai pathtools sacremoses sentence-transformers toolwrapper uctools wavedrom\n",
            "Installing collected packages: types-pyyaml, toolwrapper, sentencepiece, pydub, pathtools, openfile, nh3, fuzzywuzzy, ffmpy, docopt, bitarray, appdirs, antlr4-python3-runtime, xmltodict, websockets, uctools, uc-micro-py, typing-extensions, toolz, threadpoolctl, tabulate, svgwrite, sniffio, smmap, shortuuid, setproctitle, sentry-sdk, semantic-version, scipy, sacremoses, rapidfuzz, python-multipart, pyrsistent, protobuf, portalocker, pkgutil-resolve-name, orjson, mdurl, markupsafe, markdown2, lxml, lemminflect, importlib-resources, h11, docker-pycreds, cython, colorama, aiofiles, wavedrom, uvicorn, tiktoken, scikit-learn, sacrebleu, responses, pydantic, py3nvml, omegaconf, markdown-it-py, linkify-it-py, levenshtein, language-tool-python, jsonschema, jinja2, huggingface-hub, gitdb, anyio, transformers, starlette, python-levenshtein, openai, mdit-py-plugins, hydra-core, httpcore, gitpython, altair, wandb, httpx, fastapi, fairscale, datasets, accelerate, sentence-transformers, gradio, fairseq\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.4.0\n",
            "    Uninstalling typing_extensions-4.4.0:\n",
            "      Successfully uninstalled typing_extensions-4.4.0\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.1.1\n",
            "    Uninstalling MarkupSafe-2.1.1:\n",
            "      Successfully uninstalled MarkupSafe-2.1.1\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.4.5\n",
            "    Uninstalling importlib_resources-6.4.5:\n",
            "      Successfully uninstalled importlib_resources-6.4.5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "Successfully installed accelerate-0.16.0 aiofiles-23.1.0 altair-4.2.2 antlr4-python3-runtime-4.8 anyio-3.6.2 appdirs-1.4.4 bitarray-2.7.3 colorama-0.4.6 cython-0.29.33 datasets-2.12.0 docker-pycreds-0.4.0 docopt-0.6.2 fairscale-0.4.13 fairseq-0.12.2 fastapi-0.95.1 ffmpy-0.3.0 fuzzywuzzy-0.18.0 gitdb-4.0.10 gitpython-3.1.31 gradio-3.23.0 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.13.4 hydra-core-1.0.7 importlib-resources-5.12.0 jinja2-3.1.2 jsonschema-4.17.3 language-tool-python-2.7.1 lemminflect-0.2.3 levenshtein-0.20.9 linkify-it-py-2.0.2 lxml-4.9.2 markdown-it-py-2.2.0 markdown2-2.4.8 markupsafe-2.1.2 mdit-py-plugins-0.3.3 mdurl-0.1.2 nh3-0.2.11 omegaconf-2.0.5 openai-0.27.1 openfile-0.0.7 orjson-3.8.12 pathtools-0.1.2 pkgutil-resolve-name-1.3.10 portalocker-2.7.0 protobuf-3.20.1 py3nvml-0.2.7 pydantic-1.10.7 pydub-0.25.1 pyrsistent-0.19.3 python-levenshtein-0.20.9 python-multipart-0.0.6 rapidfuzz-2.13.7 responses-0.18.0 sacrebleu-2.3.1 sacremoses-0.0.53 scikit-learn-1.2.2 scipy-1.10.1 semantic-version-2.10.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.16.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 sniffio-1.3.0 starlette-0.26.1 svgwrite-1.4.3 tabulate-0.9.0 threadpoolctl-3.1.0 tiktoken-0.3.3 toolwrapper-2.1.0 toolz-0.12.0 transformers-4.28.1 types-pyyaml-6.0.12.9 typing-extensions-4.13.2 uc-micro-py-1.0.2 uctools-1.3.0 uvicorn-0.22.0 wandb-0.15.0 wavedrom-2.0.3.post3 websockets-11.0.3 xmltodict-0.13.0\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate chatgpt\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash miniconda.sh -bfp /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages/')\n",
        "!conda --version\n",
        "%cd /content/drive/MyDrive/SICO\n",
        "!conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/chatgpt/bin/python -m nltk.downloader all"
      ],
      "metadata": {
        "id": "VpXw09ms6081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a43813-6295-4f34-dfe2-e592612a2a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/chatgpt/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env remove -n chatgpt --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6LcA_zOM3Bu",
        "outputId": "343121a5-37c9-4c90-f17f-38e80aceb493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training dataset formating"
      ],
      "metadata": {
        "id": "nJ6UI2j8zZsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUQ5xzZoXfNU",
        "outputId": "99d392f0-190f-4bb3-d4b6-7998517737f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[K     |████████████████████████████████| 480 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting multiprocess<0.70.17\n",
            "  Downloading multiprocess-0.70.16-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 82.1 MB/s \n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 40.0 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.23.0\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 89.6 MB/s \n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting requests>=2.32.2\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.17\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 81.1 MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.66.3\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 83.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 81.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[K     |████████████████████████████████| 194 kB 96.3 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]<=2024.9.0,>=2023.1.0\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 76.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "\u001b[K     |████████████████████████████████| 746 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 102.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.12.0\n",
            "  Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[K     |████████████████████████████████| 319 kB 80.0 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 93.8 MB/s \n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting typing-extensions>=3.7.4.3\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.3)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 102.6 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 102.5 MB/s \n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 98.3 MB/s \n",
            "\u001b[?25hCollecting tzdata>=2022.1\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[K     |████████████████████████████████| 347 kB 100.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: typing-extensions, propcache, multidict, frozenlist, yarl, attrs, async-timeout, aiosignal, aiohappyeyeballs, tzdata, tqdm, requests, pyyaml, pytz, python-dateutil, packaging, numpy, fsspec, filelock, dill, aiohttp, xxhash, pyarrow, pandas, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.63.0\n",
            "    Uninstalling tqdm-4.63.0:\n",
            "      Successfully uninstalled tqdm-4.63.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 attrs-25.3.0 datasets-3.1.0 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.30.2 multidict-6.1.0 multiprocess-0.70.16 numpy-1.24.4 packaging-24.2 pandas-2.0.3 propcache-0.2.0 pyarrow-17.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 tqdm-4.67.1 typing-extensions-4.13.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.15.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pytz"
                ]
              },
              "id": "47e612a91af644dc8b2f2b698b201035"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# --- Parametry Konfiguracyjne ---\n",
        "hf_dataset_name = \"Hello-SimpleAI/HC3\"\n",
        "split_name = \"wiki_csai\"\n",
        "output_dataset_name = \"hc3_wiki\"\n",
        "\n",
        "sico_base_dir = \"/content/drive/MyDrive/SICO\"\n",
        "output_folder = os.path.join(sico_base_dir, 'datasets', output_dataset_name)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "incontext_size = 8\n",
        "eval_size = 32\n",
        "test_size = 200\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    if text is None: return \"\"\n",
        "    if isinstance(text, list):\n",
        "        if not text: return \"\"\n",
        "        text = str(text[0])\n",
        "    else:\n",
        "        text = str(text)\n",
        "    text = text.replace('\\n', ' ').replace('\\t', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "print(f\"--- Ładowanie datasetu {hf_dataset_name}, split '{split_name}' ---\", flush=True)\n",
        "try:\n",
        "    dataset = load_dataset(hf_dataset_name, name=split_name, split='train')\n",
        "    print(f\"Dataset loaded successfully. Number of records: {len(dataset)}\", flush=True)\n",
        "except Exception as e:\n",
        "    print(f\"ERROR loading dataset: {e}\", flush=True)\n",
        "    print(\"Sprawdź połączenie internetowe i nazwę datasetu/splitu.\", flush=True)\n",
        "    raise e\n",
        "\n",
        "all_triplets = []\n",
        "print(\"--- Przetwarzanie rekordów ---\", flush=True)\n",
        "count = 0\n",
        "skipped = 0\n",
        "for item in dataset:\n",
        "    count += 1\n",
        "    question = item.get('question')\n",
        "    human_answers = item.get('human_answers')\n",
        "    chatgpt_answers = item.get('chatgpt_answers')\n",
        "\n",
        "    if question and human_answers and chatgpt_answers:\n",
        "        human_ans = clean_text(human_answers)\n",
        "        ai_ans = clean_text(chatgpt_answers)\n",
        "        q_cleaned = clean_text(question)\n",
        "\n",
        "        if q_cleaned and human_ans and ai_ans:\n",
        "            all_triplets.append((q_cleaned, human_ans, ai_ans))\n",
        "        else: skipped += 1\n",
        "    else: skipped += 1\n",
        "\n",
        "print(f\"Przetworzono {count} rekordów.\", flush=True)\n",
        "print(f\"Stworzono {len(all_triplets)} poprawnych tripletów (Input, Human, AI).\", flush=True)\n",
        "print(f\"Pominięto {skipped} rekordów.\", flush=True)\n",
        "\n",
        "if not all_triplets:\n",
        "     raise ValueError(\"Nie udało się stworzyć żadnych tripletów z danych.\")\n",
        "\n",
        "print(\"\\n--- Podział danych na zbiory ---\", flush=True)\n",
        "total_needed = incontext_size + eval_size + test_size\n",
        "if len(all_triplets) < total_needed:\n",
        "     print(f\"OSTRZEŻENIE: Niewystarczająca liczba tripletów ({len(all_triplets)}) dla żądanych rozmiarów. Dostosowuję rozmiary...\", flush=True)\n",
        "     actual_incontext_size = min(incontext_size, len(all_triplets))\n",
        "     remaining_after_incontext = len(all_triplets) - actual_incontext_size\n",
        "     actual_eval_size = min(eval_size, remaining_after_incontext)\n",
        "     remaining_after_eval = remaining_after_incontext - actual_eval_size\n",
        "     actual_test_size = min(test_size, remaining_after_eval)\n",
        "     print(f\"Nowe rozmiary: In-context={actual_incontext_size}, Eval={actual_eval_size}, Test={actual_test_size}\", flush=True)\n",
        "else:\n",
        "     actual_incontext_size = incontext_size\n",
        "     actual_eval_size = eval_size\n",
        "     actual_test_size = test_size\n",
        "\n",
        "random.shuffle(all_triplets)\n",
        "incontext_data = all_triplets[:actual_incontext_size]\n",
        "eval_data = all_triplets[actual_incontext_size : actual_incontext_size + actual_eval_size]\n",
        "test_data = all_triplets[actual_incontext_size + actual_eval_size : actual_incontext_size + actual_eval_size + actual_test_size]\n",
        "\n",
        "print(f\"\\nFinalne rozmiary zbiorów:\")\n",
        "print(f\" - In-context: {len(incontext_data)}\")\n",
        "print(f\" - Evaluation: {len(eval_data)}\")\n",
        "print(f\" - Test: {len(test_data)}\")\n",
        "\n",
        "print(\"\\n--- Zapisywanie plików TSV ---\", flush=True)\n",
        "try:\n",
        "    headers = ['input', 'human', 'ai']\n",
        "\n",
        "    # incontext.tsv\n",
        "    incontext_path = os.path.join(output_folder, 'incontext.tsv')\n",
        "    df_incontext = pd.DataFrame(incontext_data, columns=headers)\n",
        "    df_incontext.to_csv(incontext_path, sep='\\t', index=False, header=True, quoting=3) # quoting=3 to csv.QUOTE_NONE\n",
        "    print(f\"Saved {incontext_path} ({len(incontext_data)} rows)\", flush=True)\n",
        "\n",
        "    # eval.tsv\n",
        "    eval_path = os.path.join(output_folder, 'eval.tsv')\n",
        "    df_eval = pd.DataFrame(eval_data, columns=headers)\n",
        "    df_eval.to_csv(eval_path, sep='\\t', index=False, header=True, quoting=3)\n",
        "    print(f\"Saved {eval_path} ({len(eval_data)} rows)\", flush=True)\n",
        "\n",
        "    # test.tsv\n",
        "    test_path = os.path.join(output_folder, 'test.tsv')\n",
        "    df_test = pd.DataFrame(test_data, columns=headers)\n",
        "    df_test.to_csv(test_path, sep='\\t', index=False, header=True, quoting=3)\n",
        "    print(f\"Saved {test_path} ({len(test_data)} rows)\", flush=True)\n",
        "\n",
        "    print(\"\\nData processing finished successfully.\", flush=True)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR during saving TSV files: {e}\", flush=True)\n",
        "    raise e"
      ],
      "metadata": {
        "id": "HpBdBYI0zY62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "92253a04-660f-4388-cc2a-a16d6adef151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70b09abda137>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;31m# Importuj bibliotekę\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# --- Parametry Konfiguracyjne ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data training"
      ],
      "metadata": {
        "id": "VmFD0dZjzgg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "teIqUbjLKkHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!OPENAI_API_KEY='sk-' /usr/local/envs/chatgpt/bin/python SICO_train.py \\\n",
        "    --dataset hc3_wiki \\\n",
        "    --llm chatgpt \\\n",
        "    --detector chatdetect \\\n",
        "    --task paraphrase \\\n",
        "    --incontext-size 8 \\\n",
        "    --eval-size 32 \\\n",
        "    --train-iter 6"
      ],
      "metadata": {
        "id": "paAlmouULytJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1583f162-f5ec-495c-a3cc-73675942caf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [2025-04-17 16:15:39.405533] SICO_train.py execution started ---\n",
            "--- [2025-04-17 16:15:43.255639] Imports finished ---\n",
            "--- [2025-04-17 16:15:43.256012] Entered __main__ block ---\n",
            "[dataloader] Loading in-context data from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/incontext.tsv\n",
            "[dataloader] Raw in-context data rows loaded: 8\n",
            "[2025-04-17 16:15:43.259276] Initializing SICOTrainer...\n",
            "\n",
            "Hyper-params\n",
            "Dataset=hc3_wiki\n",
            "LLM=chatgpt\n",
            "Detector for training=chatdetect\n",
            "Task type=paraphrase\n",
            "Generation Args:={'temperature': 1}\n",
            "Eval size=32\n",
            "ICE number=8\n",
            "Edit=Sub-Para/Word:[Word:1, Sent-8:1]\n",
            "seed=5050\n",
            "\n",
            "[2025-04-17 16:15:43.264422] Initializing wandb (disabled=True)...\n",
            "[2025-04-17 16:15:43.382727] wandb initialized successfully (mode: disabled).\n",
            "[2025-04-17 16:15:43.382774] Initializing GPU devices...\n",
            "[2025-04-17 16:15:43.400608] Found 1 GPU(s). Using cuda:0 for all tasks.\n",
            "[2025-04-17 16:15:43.400635] Initializing detector: chatdetect on cuda:0...\n",
            "Downloading tokenizer_config.json: 100% 391/391 [00:00<00:00, 52.7kB/s]\n",
            "Downloading vocab.json: 100% 798k/798k [00:00<00:00, 14.2MB/s]\n",
            "Downloading merges.txt: 100% 456k/456k [00:00<00:00, 9.59MB/s]\n",
            "Downloading tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 24.2MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 280/280 [00:00<00:00, 120kB/s]\n",
            "Downloading config.json: 100% 858/858 [00:00<00:00, 390kB/s]\n",
            "Downloading pytorch_model.bin: 100% 499M/499M [00:02<00:00, 171MB/s]\n",
            "/usr/local/envs/chatgpt/lib/python3.8/site-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "[2025-04-17 16:15:49.605525] Detector chatdetect initialized successfully.\n",
            "[2025-04-17 16:15:49.605579] Initializing LLM: chatgpt on cuda:0...\n",
            "OPENAI KEY: sk-proj--G...\n",
            "[2025-04-17 16:15:49.605638] LLM chatgpt initialized successfully.\n",
            "[2025-04-17 16:15:49.605649] Initializing candidate generators...\n",
            "[2025-04-17 16:15:51.334170] Candidate generators initialized successfully.\n",
            "[2025-04-17 16:15:51.334235] Loading evaluation data (eval_data_list)...\n",
            "[dataloader] Loading eval data from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/eval.tsv\n",
            "[dataloader] Raw eval data rows loaded: 32\n",
            "[2025-04-17 16:15:51.337587] Loaded 32 evaluation examples.\n",
            "[2025-04-17 16:15:51.339195] Results will be saved to: /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6\n",
            "[2025-04-17 16:15:51.339236] SICOTrainer initialization finished.\n",
            "\n",
            "[2025-04-17 16:15:51.339514] Starting main train() method...\n",
            "\n",
            "[2025-04-17 16:15:51.339648] Starting Step 1: Feature Extraction (extract_feature)...\n",
            "[2025-04-17 16:15:51.339776] Constructing feature extraction prompt...\n",
            "[2025-04-17 16:15:51.340312] WARNING: Feature extraction prompt too long. Truncating.\n",
            "[2025-04-17 16:15:51.340578] Feature prompt length ~1841 tokens. Max new tokens: 970\n",
            "[2025-04-17 16:15:51.340593] Calling LLM API for 5 feature candidates...\n",
            "[2025-04-17 16:16:07.093304] LLM API returned 5 feature candidates.\n",
            "[2025-04-17 16:16:07.093341] Evaluating 5 extracted features...\n",
            "[2025-04-17 16:16:07.093349]  - Evaluating feature 1/5...\n",
            "[2025-04-17 16:16:07.093370] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:16:07.093913] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:17:14.563860] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:17:14.764655] -> Detector finished.\n",
            "[2025-04-17 16:17:14.764933] -> Finished evaluate_prompt. U=0.3594, Acc=62.50%. Duration: 67.67s\n",
            "[2025-04-17 16:17:14.765506]  - Feature 1 evaluated. U=0.3594, Acc=62.50%\n",
            "[2025-04-17 16:17:14.765532]  - Evaluating feature 2/5...\n",
            "[2025-04-17 16:17:14.765553] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:17:14.765914] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:18:22.029528] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:18:22.171074] -> Detector finished.\n",
            "[2025-04-17 16:18:22.171240] -> Finished evaluate_prompt. U=0.3046, Acc=68.75%. Duration: 67.41s\n",
            "[2025-04-17 16:18:22.171630]  - Feature 2 evaluated. U=0.3046, Acc=68.75%\n",
            "[2025-04-17 16:18:22.171655]  - Evaluating feature 3/5...\n",
            "[2025-04-17 16:18:22.171691] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:18:22.172004] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:19:26.404249] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:19:26.522617] -> Detector finished.\n",
            "[2025-04-17 16:19:26.522805] -> Finished evaluate_prompt. U=0.4080, Acc=59.38%. Duration: 64.35s\n",
            "[2025-04-17 16:19:26.523295]  - Feature 3 evaluated. U=0.4080, Acc=59.38%\n",
            "[2025-04-17 16:19:26.523329]  - Evaluating feature 4/5...\n",
            "[2025-04-17 16:19:26.523351] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:19:26.523763] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:20:35.406500] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:20:35.547294] -> Detector finished.\n",
            "[2025-04-17 16:20:35.547475] -> Finished evaluate_prompt. U=0.3121, Acc=68.75%. Duration: 69.02s\n",
            "[2025-04-17 16:20:35.547951]  - Feature 4 evaluated. U=0.3121, Acc=68.75%\n",
            "[2025-04-17 16:20:35.547979]  - Evaluating feature 5/5...\n",
            "[2025-04-17 16:20:35.548007] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:20:35.548393] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:21:40.769611] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:21:40.893710] -> Detector finished.\n",
            "[2025-04-17 16:21:40.893867] -> Finished evaluate_prompt. U=0.3967, Acc=56.25%. Duration: 65.35s\n",
            "[2025-04-17 16:21:40.894304]  - Feature 5 evaluated. U=0.3967, Acc=56.25%\n",
            "\n",
            "[2025-04-17 16:21:40.894376] ================= Init Feature Result ==================\n",
            "Best U-Score: 0.4080\n",
            "Best Feature:\n",
            "there are still many open questions about the existence and smoothness of solutions to the Navier-Stokes equations, leading to one of the most famous unsolved problems in mathematics, the Clay Millennium Prize Problem on the existence and smoothness of solutions to the Navier-Stokes equations.\n",
            "\n",
            "Infrared light, also known as infrared radiation, is a type of electromagnetic radiation with wavelengths longer than those of visible light. It is invisible to the human eye but can be detected by special sensors and cameras. Infrared light is commonly used in various applications, such as thermal imaging, night vision, and communication. It has practical uses in sectors like security and surveillance, healthcare, and astronomy. The study of infrared radiation has led to advancements in technology and scientific research, contributing to the development of cutting-edge devices and systems.\n",
            "\n",
            "Multi-agent systems are computer systems composed of multiple interacting agents, each with its own goals and capabilities. These agents can work together to accomplish tasks or compete with each other in a dynamic environment. Multi-agent systems are widely used in various fields, including robotics, economics, and social sciences. They offer a flexible and scalable approach to problem-solving, enabling complex tasks to be divided among multiple agents for efficient execution. Research in multi-agent systems continues to advance, exploring new algorithms and techniques to enhance collaboration and coordination among agents.\n",
            "\n",
            "Sentence embedding is a technique used in natural language processing to represent sentences as numerical vectors in a high-dimensional space. By encoding the semantic meaning of sentences into vector representations, sentence embeddings enable machines to understand and process textual information efficiently. These embeddings are useful in tasks such as sentiment analysis, text classification, and document retrieval. Various methods, including neural networks and word embeddings, can be employed to generate sentence embeddings, providing a versatile tool for analyzing and extracting information from text data.\n",
            "\n",
            "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network architecture designed to capture long-term dependencies in sequential data. LSTMs are equipped with memory cells that store and propagate information over time, allowing them to effectively model complex patterns in input sequences. These networks have been successfully applied in various domains, including speech recognition, machine translation, and time series forecasting. Their ability to learn and remember sequential patterns makes LSTMs a powerful tool for tasks requiring memory and context preservation.\n",
            "\n",
            "Game Artificial Intelligence (AI) refers to the use of algorithms and techniques to create intelligent behavior in virtual characters and non-player entities within video games. Game AI plays a crucial role in enhancing player experiences by providing challenging opponents, realistic behaviors, and dynamic environments. Techniques like pathfinding, decision-making, and strategic planning are commonly used in game AI development to create engaging and interactive gameplay. The field of game AI continues to evolve, with advancements in machine learning and reinforcement learning enabling more sophisticated and adaptive game behaviors. As the gaming industry grows, the demand for innovative and advanced game AI solutions is on the rise, driving research and development in this exciting field.\n",
            "=========================================================\n",
            "[2025-04-17 16:21:40.894584] Finished Step 1: Feature Extraction. Duration: 349.55s\n",
            "\n",
            "[2025-04-17 16:21:40.894716] Starting Step 2: Construct initial y_ic (construct_incontext_outputs)...\n",
            "[2025-04-17 16:21:40.894871] Generating 8 initial y_ic examples via LLM API...\n",
            "Construct y_ic: 100% 8/8 [00:16<00:00,  2.07s/it]\n",
            "[2025-04-17 16:21:57.448757] Finished Step 2: Constructing y_ic. Duration: 16.55s\n",
            "[2025-04-17 16:21:57.449418] Evaluating initial prompt...\n",
            "[2025-04-17 16:21:57.449444] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:21:57.450460] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:23:09.400993] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:23:09.518239] -> Detector finished.\n",
            "[2025-04-17 16:23:09.518404] -> Finished evaluate_prompt. U=0.4876, Acc=46.88%. Duration: 72.07s\n",
            "[2025-04-17 16:23:09.518858] Initial prompt evaluation complete. Score (1-P_AI): 0.4876, Detection Acc: 46.88%\n",
            "[2025-04-17 16:23:09.518923] ---> Saving step '0' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:23:09.526868] ---> Step '0' data saved successfully.\n",
            "\n",
            "[2025-04-17 16:23:09.527177] === Starting Main Training Loop (6 iterations planned) ===\n",
            "[2025-04-17 16:23:09.527197] Initial Best Score (1-P_AI): 0.4876, Initial Detection Acc: 46.88%\n",
            "Main Training Loop:   0% 0/6 [00:00<?, ?it/s]\n",
            "[2025-04-17 16:23:09.527427] === Starting Training Iteration 1/6 ===\n",
            "[2025-04-17 16:23:09.527546] Iter 1: Optimizing type: sent\n",
            "[2025-04-17 16:23:09.527559] Iter 1: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:23:09.527572] ----> Starting example optimization (_optimize_ic_outputs, type: 'sent')...\n",
            "[2025-04-17 16:23:09.527734] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:23:09.527758] ------> Optimizing example 1/8 (type: sent)...\n",
            "[2025-04-17 16:23:20.490971] ---------> Example 1 optimized. Human-score: 0.9986. Detector queries: 48\n",
            "[2025-04-17 16:23:20.491077] ------> Finished optimizing example 1. Duration: 10.96s\n",
            "[2025-04-17 16:23:20.491097] ------> Optimizing example 2/8 (type: sent)...\n",
            "[2025-04-17 16:23:27.239284] ---------> Example 2 optimized. Human-score: 0.9806. Detector queries: 32\n",
            "[2025-04-17 16:23:27.239364] ------> Finished optimizing example 2. Duration: 6.75s\n",
            "[2025-04-17 16:23:27.239382] ------> Optimizing example 3/8 (type: sent)...\n",
            "[2025-04-17 16:23:36.446807] ---------> Example 3 optimized. Human-score: 0.9892. Detector queries: 56\n",
            "[2025-04-17 16:23:36.446886] ------> Finished optimizing example 3. Duration: 9.21s\n",
            "[2025-04-17 16:23:36.446904] ------> Optimizing example 4/8 (type: sent)...\n",
            "[2025-04-17 16:23:41.043364] ---------> Example 4 optimized. Human-score: 0.9987. Detector queries: 32\n",
            "[2025-04-17 16:23:41.043453] ------> Finished optimizing example 4. Duration: 4.60s\n",
            "[2025-04-17 16:23:41.043472] ------> Optimizing example 5/8 (type: sent)...\n",
            "[2025-04-17 16:23:47.468681] ---------> Example 5 optimized. Human-score: 0.9963. Detector queries: 40\n",
            "[2025-04-17 16:23:47.468779] ------> Finished optimizing example 5. Duration: 6.43s\n",
            "[2025-04-17 16:23:47.468797] ------> Optimizing example 6/8 (type: sent)...\n",
            "[2025-04-17 16:23:54.625264] ---------> Example 6 optimized. Human-score: 0.9983. Detector queries: 40\n",
            "[2025-04-17 16:23:54.625350] ------> Finished optimizing example 6. Duration: 7.16s\n",
            "[2025-04-17 16:23:54.625369] ------> Optimizing example 7/8 (type: sent)...\n",
            "[2025-04-17 16:24:00.773173] ---------> Example 7 optimized. Human-score: 0.9997. Detector queries: 40\n",
            "[2025-04-17 16:24:00.773253] ------> Finished optimizing example 7. Duration: 6.15s\n",
            "[2025-04-17 16:24:00.773271] ------> Optimizing example 8/8 (type: sent)...\n",
            "[2025-04-17 16:24:06.434632] ---------> Example 8 optimized. Human-score: 0.9996. Detector queries: 40\n",
            "[2025-04-17 16:24:06.434725] ------> Finished optimizing example 8. Duration: 5.66s\n",
            "[2025-04-17 16:24:06.434820] ----> Finished optimization type 'sent'. Avg human-score: 0.9951. Total detector queries: 328. Duration: 56.91s\n",
            "[2025-04-17 16:24:06.435214] Iter 1: -> Finished example optimization. Avg human-score: 0.9951. Duration: 56.91s\n",
            "[2025-04-17 16:24:06.435253] Iter 1: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:24:06.435267] --> Starting eval_and_save for step 1...\n",
            "[2025-04-17 16:24:06.435506] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:24:06.436481] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:25:21.806662] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:25:21.946896] -> Detector finished.\n",
            "[2025-04-17 16:25:21.947065] -> Finished evaluate_prompt. U=0.6154, Acc=34.38%. Duration: 75.51s\n",
            "[2025-04-17 16:25:21.947454] --> Saving generated texts for step 1...\n",
            "[2025-04-17 16:25:21.947512] ---> Saving text list '1' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_1.tsv...\n",
            "[2025-04-17 16:25:21.953095] --> Saving prompt/examples for step 1...\n",
            "[2025-04-17 16:25:21.953162] ---> Saving step '1' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:25:21.971803] ---> Step '1' data saved successfully.\n",
            "[2025-04-17 16:25:21.972145] --> !!! NEW BEST SCORE !!! Step: 1, Score: 0.6154, Acc: 34.38%\n",
            "[2025-04-17 16:25:21.972170] --> Saving new best prompt/examples...\n",
            "[2025-04-17 16:25:21.972213] ---> Saving step 'best' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:25:21.981464] ---> Step 'best' data saved successfully.\n",
            "[2025-04-17 16:25:21.981514] --> Finished eval_and_save for step 1. Duration: 75.55s\n",
            "[2025-04-17 16:25:21.981778] Iter 1: -> Finished evaluation and saving. Best score updated: True. Duration: 75.55s\n",
            "[2025-04-17 16:25:21.981800] === Finished Training Iteration 1. Iteration Duration: 132.45s ===\n",
            "Main Training Loop:  17% 1/6 [02:12<11:02, 132.45s/it]\n",
            "[2025-04-17 16:25:21.982080] === Starting Training Iteration 2/6 ===\n",
            "[2025-04-17 16:25:21.982271] Iter 2: Optimizing type: word\n",
            "[2025-04-17 16:25:21.982287] Iter 2: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:25:21.982299] ----> Starting example optimization (_optimize_ic_outputs, type: 'word')...\n",
            "[2025-04-17 16:25:21.982427] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:25:21.982443] ------> Optimizing example 1/8 (type: word)...\n",
            "[2025-04-17 16:25:25.769511] ------> ERROR generating/optimizing candidates for example 0: CUDA out of memory. Tried to allocate 24.45 GiB. GPU 0 has a total capacity of 39.56 GiB of which 13.75 GiB is free. Process 266738 has 25.79 GiB memory in use. Of the allocated memory 25.23 GiB is allocated by PyTorch, and 78.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:25.785170] ------> Finished optimizing example 1. Duration: 3.80s\n",
            "[2025-04-17 16:25:25.785226] ------> Optimizing example 2/8 (type: word)...\n",
            "[2025-04-17 16:25:27.493524] ---------> Example 2 optimized. Human-score: 0.9997. Detector queries: 101\n",
            "[2025-04-17 16:25:27.493609] ------> Finished optimizing example 2. Duration: 1.71s\n",
            "[2025-04-17 16:25:27.493627] ------> Optimizing example 3/8 (type: word)...\n",
            "[2025-04-17 16:25:28.829484] ------> ERROR generating/optimizing candidates for example 2: CUDA out of memory. Tried to allocate 20.13 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 9.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:28.843799] ------> Finished optimizing example 3. Duration: 1.35s\n",
            "[2025-04-17 16:25:28.843853] ------> Optimizing example 4/8 (type: word)...\n",
            "[2025-04-17 16:25:29.882194] ------> ERROR generating/optimizing candidates for example 3: CUDA out of memory. Tried to allocate 15.53 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 16.31 GiB is allocated by PyTorch, and 14.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:29.895603] ------> Finished optimizing example 4. Duration: 1.05s\n",
            "[2025-04-17 16:25:29.895656] ------> Optimizing example 5/8 (type: word)...\n",
            "[2025-04-17 16:25:31.142469] ------> ERROR generating/optimizing candidates for example 4: CUDA out of memory. Tried to allocate 18.98 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 11.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:31.156654] ------> Finished optimizing example 5. Duration: 1.26s\n",
            "[2025-04-17 16:25:31.156731] ------> Optimizing example 6/8 (type: word)...\n",
            "[2025-04-17 16:25:32.611944] ------> ERROR generating/optimizing candidates for example 5: CUDA out of memory. Tried to allocate 22.15 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 7.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:32.625646] ------> Finished optimizing example 6. Duration: 1.47s\n",
            "[2025-04-17 16:25:32.625713] ------> Optimizing example 7/8 (type: word)...\n",
            "[2025-04-17 16:25:34.193789] ------> ERROR generating/optimizing candidates for example 6: CUDA out of memory. Tried to allocate 23.87 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 24.65 GiB is allocated by PyTorch, and 6.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:34.207727] ------> Finished optimizing example 7. Duration: 1.58s\n",
            "[2025-04-17 16:25:34.207774] ------> Optimizing example 8/8 (type: word)...\n",
            "[2025-04-17 16:25:35.562087] ------> ERROR generating/optimizing candidates for example 7: CUDA out of memory. Tried to allocate 20.71 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.30 GiB is free. Process 266738 has 31.25 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 9.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:25:35.575814] ------> Finished optimizing example 8. Duration: 1.37s\n",
            "[2025-04-17 16:25:35.575906] ----> Finished optimization type 'word'. Avg human-score: 0.9975. Total detector queries: 101. Duration: 13.59s\n",
            "[2025-04-17 16:25:35.576135] Iter 2: -> Finished example optimization. Avg human-score: 0.9975. Duration: 13.59s\n",
            "[2025-04-17 16:25:35.576168] Iter 2: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:25:35.576181] --> Starting eval_and_save for step 2...\n",
            "[2025-04-17 16:25:35.576387] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:25:35.577351] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:27:00.087981] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:27:00.243673] -> Detector finished.\n",
            "[2025-04-17 16:27:00.243884] -> Finished evaluate_prompt. U=0.7458, Acc=18.75%. Duration: 84.67s\n",
            "[2025-04-17 16:27:00.244326] --> Saving generated texts for step 2...\n",
            "[2025-04-17 16:27:00.244400] ---> Saving text list '2' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_2.tsv...\n",
            "[2025-04-17 16:27:00.250198] --> Saving prompt/examples for step 2...\n",
            "[2025-04-17 16:27:00.250271] ---> Saving step '2' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:27:00.258217] ---> Step '2' data saved successfully.\n",
            "[2025-04-17 16:27:00.258526] --> !!! NEW BEST SCORE !!! Step: 2, Score: 0.7458, Acc: 18.75%\n",
            "[2025-04-17 16:27:00.258548] --> Saving new best prompt/examples...\n",
            "[2025-04-17 16:27:00.258579] ---> Saving step 'best' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:27:00.266210] ---> Step 'best' data saved successfully.\n",
            "[2025-04-17 16:27:00.266254] --> Finished eval_and_save for step 2. Duration: 84.69s\n",
            "[2025-04-17 16:27:00.266431] Iter 2: -> Finished evaluation and saving. Best score updated: True. Duration: 84.69s\n",
            "[2025-04-17 16:27:00.266449] === Finished Training Iteration 2. Iteration Duration: 98.28s ===\n",
            "Main Training Loop:  33% 2/6 [03:50<07:29, 112.35s/it]\n",
            "[2025-04-17 16:27:00.266663] === Starting Training Iteration 3/6 ===\n",
            "[2025-04-17 16:27:00.266811] Iter 3: Optimizing type: sent\n",
            "[2025-04-17 16:27:00.266825] Iter 3: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:27:00.266833] ----> Starting example optimization (_optimize_ic_outputs, type: 'sent')...\n",
            "[2025-04-17 16:27:00.266912] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:27:00.266926] ------> Optimizing example 1/8 (type: sent)...\n",
            "[2025-04-17 16:27:08.705774] ---------> Example 1 optimized. Human-score: 0.9994. Detector queries: 48\n",
            "[2025-04-17 16:27:08.705849] ------> Finished optimizing example 1. Duration: 8.44s\n",
            "[2025-04-17 16:27:08.705867] ------> Optimizing example 2/8 (type: sent)...\n",
            "[2025-04-17 16:27:13.926318] ---------> Example 2 optimized. Human-score: 0.9997. Detector queries: 32\n",
            "[2025-04-17 16:27:13.926394] ------> Finished optimizing example 2. Duration: 5.22s\n",
            "[2025-04-17 16:27:13.926412] ------> Optimizing example 3/8 (type: sent)...\n",
            "[2025-04-17 16:27:22.574222] ---------> Example 3 optimized. Human-score: 0.9995. Detector queries: 56\n",
            "[2025-04-17 16:27:22.574305] ------> Finished optimizing example 3. Duration: 8.65s\n",
            "[2025-04-17 16:27:22.574324] ------> Optimizing example 4/8 (type: sent)...\n",
            "[2025-04-17 16:27:29.449139] ---------> Example 4 optimized. Human-score: 0.9994. Detector queries: 32\n",
            "[2025-04-17 16:27:29.449244] ------> Finished optimizing example 4. Duration: 6.87s\n",
            "[2025-04-17 16:27:29.449262] ------> Optimizing example 5/8 (type: sent)...\n",
            "[2025-04-17 16:27:35.873292] ---------> Example 5 optimized. Human-score: 0.9996. Detector queries: 40\n",
            "[2025-04-17 16:27:35.873369] ------> Finished optimizing example 5. Duration: 6.42s\n",
            "[2025-04-17 16:27:35.873386] ------> Optimizing example 6/8 (type: sent)...\n",
            "[2025-04-17 16:27:42.454779] ---------> Example 6 optimized. Human-score: 0.9995. Detector queries: 48\n",
            "[2025-04-17 16:27:42.454858] ------> Finished optimizing example 6. Duration: 6.58s\n",
            "[2025-04-17 16:27:42.454876] ------> Optimizing example 7/8 (type: sent)...\n",
            "Text: Long Short-Term Memory (LSTM) networks, a specialized variant of recurrent neural networks (RNNs), are adept at capturing intricate patterns in sequential data, including but not limited to time series and natural language. In contrast to conventional RNNs, LSTMs handle input sequences on a step-by-step basis while preserving an internal state that stores data from preceding elements in the sequence. LSTMs are tailored to overcome the issues of vanishing and exploding gradients that can impede the learning process of conventional RNNs, allowing them to effectively capture extended dependencies in the input data.  \n",
            "\n",
            "With a cellular structure featuring input gates, output gates, and forget gates, LSTMs have the ability to selectively store or discard information within their internal state and control the movement of data in and out of the cell. LSTMs have been utilized in various domains such as language translation, speech recognition, time series forecasting, text generation, music creation, and modeling biological sequences like DNA.\n",
            "Join Text: Long Short-Term Memory (LSTM) networks, a specialized variant of recurrent neural networks (RNNs), are adept at capturing intricate patterns in sequential data, including but not limited to time series and natural language. In contrast to conventional RNNs, LSTMs handle input sequences on a step-by-step basis while preserving an internal state that stores data from preceding elements in the sequence. LSTMs are tailored to overcome the issues of vanishing and exploding gradients that can impede the learning process of conventional RNNs, allowing them to effectively capture extended dependencies in the input data. With a cellular structure featuring input gates, output gates, and forget gates, LSTMs have the ability to selectively store or discard information within their internal state and control the movement of data in and out of the cell. LSTMs have been utilized in various domains such as language translation, speech recognition, time series forecasting, text generation, music creation, and modeling biological sequences like DNA.\n",
            "[2025-04-17 16:27:49.993946] ---------> Example 7 optimized. Human-score: 0.9997. Detector queries: 40\n",
            "[2025-04-17 16:27:49.994023] ------> Finished optimizing example 7. Duration: 7.54s\n",
            "[2025-04-17 16:27:49.994042] ------> Optimizing example 8/8 (type: sent)...\n",
            "Text: Game AI, an abbreviation of artificial intelligence within the gaming industry, encompasses the application of computer algorithms and methodologies to instill intelligent actions in virtual characters and non-player entities. The utilization of Game Artificial Intelligence (AI) serves to enrich player experiences by offering authentic and captivating interactions within the gaming environment. Game AI development utilizes a variety of methods including rule-based systems, decision trees, and machine learning algorithms to create intelligent behavior in virtual characters and non-player entities within video games. \n",
            "Game AI applications encompass tasks such as pathfinding for character movement, decision-making for actions, and strategic planning for gameplay dynamics. Game Artificial Intelligence (AI) is a pivotal component in contemporary video games, crucial for crafting engaging and absorbing gaming experiences. This field is a prominent area of study within computer science, characterized by continuous research and innovation aimed at enhancing player interactions and game dynamics.\n",
            "Join Text: Game AI, an abbreviation of artificial intelligence within the gaming industry, encompasses the application of computer algorithms and methodologies to instill intelligent actions in virtual characters and non-player entities. The utilization of Game Artificial Intelligence (AI) serves to enrich player experiences by offering authentic and captivating interactions within the gaming environment. Game AI development utilizes a variety of methods including rule-based systems, decision trees, and machine learning algorithms to create intelligent behavior in virtual characters and non-player entities within video games. Game AI applications encompass tasks such as pathfinding for character movement, decision-making for actions, and strategic planning for gameplay dynamics. Game Artificial Intelligence (AI) is a pivotal component in contemporary video games, crucial for crafting engaging and absorbing gaming experiences. This field is a prominent area of study within computer science, characterized by continuous research and innovation aimed at enhancing player interactions and game dynamics.\n",
            "[2025-04-17 16:27:55.512009] ---------> Example 8 optimized. Human-score: 0.9996. Detector queries: 48\n",
            "[2025-04-17 16:27:55.512092] ------> Finished optimizing example 8. Duration: 5.52s\n",
            "[2025-04-17 16:27:55.512187] ----> Finished optimization type 'sent'. Avg human-score: 0.9995. Total detector queries: 344. Duration: 55.25s\n",
            "[2025-04-17 16:27:55.512586] Iter 3: -> Finished example optimization. Avg human-score: 0.9995. Duration: 55.25s\n",
            "[2025-04-17 16:27:55.512624] Iter 3: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:27:55.512636] --> Starting eval_and_save for step 3...\n",
            "[2025-04-17 16:27:55.512915] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:27:55.513895] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:29:14.354310] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:29:14.478848] -> Detector finished.\n",
            "[2025-04-17 16:29:14.479030] -> Finished evaluate_prompt. U=0.6658, Acc=31.25%. Duration: 78.97s\n",
            "[2025-04-17 16:29:14.479428] --> Saving generated texts for step 3...\n",
            "[2025-04-17 16:29:14.479493] ---> Saving text list '3' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_3.tsv...\n",
            "[2025-04-17 16:29:14.485085] --> Saving prompt/examples for step 3...\n",
            "[2025-04-17 16:29:14.485165] ---> Saving step '3' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:29:14.492310] ---> Step '3' data saved successfully.\n",
            "[2025-04-17 16:29:14.492600] --> Score in step 3 (0.6658) not better than best (0.7458).\n",
            "[2025-04-17 16:29:14.492655] --> Finished eval_and_save for step 3. Duration: 78.98s\n",
            "[2025-04-17 16:29:14.492867] Iter 3: -> Finished evaluation and saving. Best score updated: False. Duration: 78.98s\n",
            "[2025-04-17 16:29:14.492896] === Finished Training Iteration 3. Iteration Duration: 134.23s ===\n",
            "Main Training Loop:  50% 3/6 [06:04<06:07, 122.34s/it]\n",
            "[2025-04-17 16:29:14.493140] === Starting Training Iteration 4/6 ===\n",
            "[2025-04-17 16:29:14.493320] Iter 4: Optimizing type: word\n",
            "[2025-04-17 16:29:14.493344] Iter 4: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:29:14.493353] ----> Starting example optimization (_optimize_ic_outputs, type: 'word')...\n",
            "[2025-04-17 16:29:14.493449] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:29:14.493464] ------> Optimizing example 1/8 (type: word)...\n",
            "[2025-04-17 16:29:16.144813] ------> ERROR generating/optimizing candidates for example 0: CUDA out of memory. Tried to allocate 24.45 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 25.23 GiB is allocated by PyTorch, and 4.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:16.159935] ------> Finished optimizing example 1. Duration: 1.67s\n",
            "[2025-04-17 16:29:16.159991] ------> Optimizing example 2/8 (type: word)...\n",
            "[2025-04-17 16:29:17.118969] ------> ERROR generating/optimizing candidates for example 1: CUDA out of memory. Tried to allocate 14.67 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 13.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:17.132596] ------> Finished optimizing example 2. Duration: 0.97s\n",
            "[2025-04-17 16:29:17.132652] ------> Optimizing example 3/8 (type: word)...\n",
            "[2025-04-17 16:29:18.450746] ------> ERROR generating/optimizing candidates for example 2: CUDA out of memory. Tried to allocate 20.13 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 8.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:18.464630] ------> Finished optimizing example 3. Duration: 1.33s\n",
            "[2025-04-17 16:29:18.464697] ------> Optimizing example 4/8 (type: word)...\n",
            "[2025-04-17 16:29:19.483190] ------> ERROR generating/optimizing candidates for example 3: CUDA out of memory. Tried to allocate 15.53 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 16.31 GiB is allocated by PyTorch, and 13.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:19.496472] ------> Finished optimizing example 4. Duration: 1.03s\n",
            "[2025-04-17 16:29:19.496525] ------> Optimizing example 5/8 (type: word)...\n",
            "[2025-04-17 16:29:20.727507] ------> ERROR generating/optimizing candidates for example 4: CUDA out of memory. Tried to allocate 18.98 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 9.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:20.741803] ------> Finished optimizing example 5. Duration: 1.25s\n",
            "[2025-04-17 16:29:20.741854] ------> Optimizing example 6/8 (type: word)...\n",
            "[2025-04-17 16:29:22.178332] ------> ERROR generating/optimizing candidates for example 5: CUDA out of memory. Tried to allocate 22.15 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 6.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:22.191716] ------> Finished optimizing example 6. Duration: 1.45s\n",
            "[2025-04-17 16:29:22.191766] ------> Optimizing example 7/8 (type: word)...\n",
            "[2025-04-17 16:29:23.742271] ------> ERROR generating/optimizing candidates for example 6: CUDA out of memory. Tried to allocate 23.87 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 24.65 GiB is allocated by PyTorch, and 4.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:23.756231] ------> Finished optimizing example 7. Duration: 1.56s\n",
            "[2025-04-17 16:29:23.756284] ------> Optimizing example 8/8 (type: word)...\n",
            "[2025-04-17 16:29:25.103718] ------> ERROR generating/optimizing candidates for example 7: CUDA out of memory. Tried to allocate 20.71 GiB. GPU 0 has a total capacity of 39.56 GiB of which 9.74 GiB is free. Process 266738 has 29.81 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 7.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:29:25.117888] ------> Finished optimizing example 8. Duration: 1.36s\n",
            "[2025-04-17 16:29:25.117986] ----> Finished optimization type 'word'. Avg human-score: 0.9975. Total detector queries: 0. Duration: 10.62s\n",
            "[2025-04-17 16:29:25.118238] Iter 4: -> Finished example optimization. Avg human-score: 0.9975. Duration: 10.62s\n",
            "[2025-04-17 16:29:25.118272] Iter 4: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:29:25.118286] --> Starting eval_and_save for step 4...\n",
            "[2025-04-17 16:29:25.118493] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:29:25.119467] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:30:46.973810] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:30:47.119973] -> Detector finished.\n",
            "[2025-04-17 16:30:47.120150] -> Finished evaluate_prompt. U=0.6638, Acc=28.12%. Duration: 82.00s\n",
            "[2025-04-17 16:30:47.120565] --> Saving generated texts for step 4...\n",
            "[2025-04-17 16:30:47.120627] ---> Saving text list '4' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_4.tsv...\n",
            "[2025-04-17 16:30:47.134413] --> Saving prompt/examples for step 4...\n",
            "[2025-04-17 16:30:47.134486] ---> Saving step '4' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:30:47.142861] ---> Step '4' data saved successfully.\n",
            "[2025-04-17 16:30:47.143065] --> Score in step 4 (0.6638) not better than best (0.7458).\n",
            "[2025-04-17 16:30:47.143102] --> Finished eval_and_save for step 4. Duration: 82.02s\n",
            "[2025-04-17 16:30:47.143231] Iter 4: -> Finished evaluation and saving. Best score updated: False. Duration: 82.02s\n",
            "[2025-04-17 16:30:47.143247] === Finished Training Iteration 4. Iteration Duration: 92.65s ===\n",
            "Main Training Loop:  67% 4/6 [07:37<03:41, 110.62s/it]\n",
            "[2025-04-17 16:30:47.143442] === Starting Training Iteration 5/6 ===\n",
            "[2025-04-17 16:30:47.143552] Iter 5: Optimizing type: sent\n",
            "[2025-04-17 16:30:47.143565] Iter 5: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:30:47.143574] ----> Starting example optimization (_optimize_ic_outputs, type: 'sent')...\n",
            "[2025-04-17 16:30:47.143670] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:30:47.143697] ------> Optimizing example 1/8 (type: sent)...\n",
            "[2025-04-17 16:30:59.223635] ---------> Example 1 optimized. Human-score: 0.9995. Detector queries: 48\n",
            "[2025-04-17 16:30:59.223736] ------> Finished optimizing example 1. Duration: 12.08s\n",
            "[2025-04-17 16:30:59.223755] ------> Optimizing example 2/8 (type: sent)...\n",
            "[2025-04-17 16:31:03.784582] ---------> Example 2 optimized. Human-score: 0.9997. Detector queries: 32\n",
            "[2025-04-17 16:31:03.784661] ------> Finished optimizing example 2. Duration: 4.56s\n",
            "[2025-04-17 16:31:03.784707] ------> Optimizing example 3/8 (type: sent)...\n",
            "[2025-04-17 16:31:12.325763] ---------> Example 3 optimized. Human-score: 0.9986. Detector queries: 56\n",
            "[2025-04-17 16:31:12.325845] ------> Finished optimizing example 3. Duration: 8.54s\n",
            "[2025-04-17 16:31:12.325883] ------> Optimizing example 4/8 (type: sent)...\n",
            "[2025-04-17 16:31:17.164556] ---------> Example 4 optimized. Human-score: 0.9994. Detector queries: 32\n",
            "[2025-04-17 16:31:17.164636] ------> Finished optimizing example 4. Duration: 4.84s\n",
            "[2025-04-17 16:31:17.164657] ------> Optimizing example 5/8 (type: sent)...\n",
            "[2025-04-17 16:31:22.653876] ---------> Example 5 optimized. Human-score: 0.9996. Detector queries: 40\n",
            "[2025-04-17 16:31:22.653954] ------> Finished optimizing example 5. Duration: 5.49s\n",
            "[2025-04-17 16:31:22.653972] ------> Optimizing example 6/8 (type: sent)...\n",
            "[2025-04-17 16:31:31.574719] ---------> Example 6 optimized. Human-score: 0.9996. Detector queries: 48\n",
            "[2025-04-17 16:31:31.574794] ------> Finished optimizing example 6. Duration: 8.92s\n",
            "[2025-04-17 16:31:31.574812] ------> Optimizing example 7/8 (type: sent)...\n",
            "Text: Long Short-Term Memory (LSTM) networks, a specialized variant of recurrent neural networks (RNNs), are adept at capturing intricate patterns in sequential data, including but not limited to time series and natural language. In contrast to conventional RNNs, LSTMs handle input sequences on a step-by-step basis while preserving an internal state that stores data from preceding elements in the sequence. LSTMs are tailored to overcome the issues of vanishing and exploding gradients that can impede the learning process of conventional RNNs, allowing them to effectively capture extended dependencies in the input data.  \n",
            "\n",
            "With a cellular structure featuring input gates, output gates, and forget gates, LSTMs have the ability to selectively store or discard information within their internal state and control the movement of data in and out of the cell. LSTMs have been utilized in various domains such as language translation, speech recognition, time series forecasting, text generation, music creation, and modeling biological sequences like DNA.\n",
            "Join Text: Long Short-Term Memory (LSTM) networks, a specialized variant of recurrent neural networks (RNNs), are adept at capturing intricate patterns in sequential data, including but not limited to time series and natural language. In contrast to conventional RNNs, LSTMs handle input sequences on a step-by-step basis while preserving an internal state that stores data from preceding elements in the sequence. LSTMs are tailored to overcome the issues of vanishing and exploding gradients that can impede the learning process of conventional RNNs, allowing them to effectively capture extended dependencies in the input data. With a cellular structure featuring input gates, output gates, and forget gates, LSTMs have the ability to selectively store or discard information within their internal state and control the movement of data in and out of the cell. LSTMs have been utilized in various domains such as language translation, speech recognition, time series forecasting, text generation, music creation, and modeling biological sequences like DNA.\n",
            "[2025-04-17 16:31:41.881125] ---------> Example 7 optimized. Human-score: 0.9997. Detector queries: 40\n",
            "[2025-04-17 16:31:41.881202] ------> Finished optimizing example 7. Duration: 10.31s\n",
            "[2025-04-17 16:31:41.881222] ------> Optimizing example 8/8 (type: sent)...\n",
            "Text: Game AI, an abbreviation of artificial intelligence within the gaming industry, encompasses the application of computer algorithms and methodologies to instill intelligent actions in virtual characters and non-player entities. The utilization of Game Artificial Intelligence (AI) serves to enrich player experiences by offering authentic and captivating interactions within the gaming environment. Game AI development utilizes a variety of methods including rule-based systems, decision trees, and machine learning algorithms to create intelligent behavior in virtual characters and non-player entities within video games. \n",
            "Game AI applications encompass tasks such as pathfinding for character movement, decision-making for actions, and strategic planning for gameplay dynamics. Game Artificial Intelligence (AI) is a pivotal component in contemporary video games, crucial for crafting engaging and absorbing gaming experiences. This field is a prominent area of study within computer science, characterized by continuous research and innovation aimed at enhancing player interactions and game dynamics.\n",
            "Join Text: Game AI, an abbreviation of artificial intelligence within the gaming industry, encompasses the application of computer algorithms and methodologies to instill intelligent actions in virtual characters and non-player entities. The utilization of Game Artificial Intelligence (AI) serves to enrich player experiences by offering authentic and captivating interactions within the gaming environment. Game AI development utilizes a variety of methods including rule-based systems, decision trees, and machine learning algorithms to create intelligent behavior in virtual characters and non-player entities within video games. Game AI applications encompass tasks such as pathfinding for character movement, decision-making for actions, and strategic planning for gameplay dynamics. Game Artificial Intelligence (AI) is a pivotal component in contemporary video games, crucial for crafting engaging and absorbing gaming experiences. This field is a prominent area of study within computer science, characterized by continuous research and innovation aimed at enhancing player interactions and game dynamics.\n",
            "[2025-04-17 16:31:48.903924] ---------> Example 8 optimized. Human-score: 0.9996. Detector queries: 48\n",
            "[2025-04-17 16:31:48.904013] ------> Finished optimizing example 8. Duration: 7.02s\n",
            "[2025-04-17 16:31:48.904114] ----> Finished optimization type 'sent'. Avg human-score: 0.9994. Total detector queries: 344. Duration: 61.76s\n",
            "[2025-04-17 16:31:48.904529] Iter 5: -> Finished example optimization. Avg human-score: 0.9994. Duration: 61.76s\n",
            "[2025-04-17 16:31:48.904570] Iter 5: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:31:48.904583] --> Starting eval_and_save for step 5...\n",
            "[2025-04-17 16:31:48.904832] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:31:48.905829] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:33:09.009236] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:33:09.149627] -> Detector finished.\n",
            "[2025-04-17 16:33:09.149951] -> Finished evaluate_prompt. U=0.6776, Acc=31.25%. Duration: 80.24s\n",
            "[2025-04-17 16:33:09.150366] --> Saving generated texts for step 5...\n",
            "[2025-04-17 16:33:09.150431] ---> Saving text list '5' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_5.tsv...\n",
            "[2025-04-17 16:33:09.156106] --> Saving prompt/examples for step 5...\n",
            "[2025-04-17 16:33:09.156168] ---> Saving step '5' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:33:09.163019] ---> Step '5' data saved successfully.\n",
            "[2025-04-17 16:33:09.163228] --> Score in step 5 (0.6776) not better than best (0.7458).\n",
            "[2025-04-17 16:33:09.163259] --> Finished eval_and_save for step 5. Duration: 80.26s\n",
            "[2025-04-17 16:33:09.163392] Iter 5: -> Finished evaluation and saving. Best score updated: False. Duration: 80.26s\n",
            "[2025-04-17 16:33:09.163408] === Finished Training Iteration 5. Iteration Duration: 142.02s ===\n",
            "Main Training Loop:  83% 5/6 [09:59<02:01, 121.94s/it]\n",
            "[2025-04-17 16:33:09.163609] === Starting Training Iteration 6/6 ===\n",
            "[2025-04-17 16:33:09.163796] Iter 6: Optimizing type: word\n",
            "[2025-04-17 16:33:09.163811] Iter 6: -> Starting example optimization (_optimize_ic_outputs)...\n",
            "[2025-04-17 16:33:09.163819] ----> Starting example optimization (_optimize_ic_outputs, type: 'word')...\n",
            "[2025-04-17 16:33:09.163904] ----> Optimizing 8 examples one by one...\n",
            "[2025-04-17 16:33:09.163917] ------> Optimizing example 1/8 (type: word)...\n",
            "[2025-04-17 16:33:10.801920] ------> ERROR generating/optimizing candidates for example 0: CUDA out of memory. Tried to allocate 24.45 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 25.23 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:10.816410] ------> Finished optimizing example 1. Duration: 1.65s\n",
            "[2025-04-17 16:33:10.816469] ------> Optimizing example 2/8 (type: word)...\n",
            "[2025-04-17 16:33:11.768649] ------> ERROR generating/optimizing candidates for example 1: CUDA out of memory. Tried to allocate 14.67 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 15.45 GiB is allocated by PyTorch, and 12.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:11.782259] ------> Finished optimizing example 2. Duration: 0.97s\n",
            "[2025-04-17 16:33:11.782311] ------> Optimizing example 3/8 (type: word)...\n",
            "[2025-04-17 16:33:13.101413] ------> ERROR generating/optimizing candidates for example 2: CUDA out of memory. Tried to allocate 20.13 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 20.91 GiB is allocated by PyTorch, and 6.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:13.115007] ------> Finished optimizing example 3. Duration: 1.33s\n",
            "[2025-04-17 16:33:13.115059] ------> Optimizing example 4/8 (type: word)...\n",
            "[2025-04-17 16:33:14.133410] ------> ERROR generating/optimizing candidates for example 3: CUDA out of memory. Tried to allocate 15.53 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 16.31 GiB is allocated by PyTorch, and 11.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:14.146657] ------> Finished optimizing example 4. Duration: 1.03s\n",
            "[2025-04-17 16:33:14.146724] ------> Optimizing example 5/8 (type: word)...\n",
            "[2025-04-17 16:33:15.377512] ------> ERROR generating/optimizing candidates for example 4: CUDA out of memory. Tried to allocate 18.98 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 19.76 GiB is allocated by PyTorch, and 8.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:15.391471] ------> Finished optimizing example 5. Duration: 1.24s\n",
            "[2025-04-17 16:33:15.391526] ------> Optimizing example 6/8 (type: word)...\n",
            "[2025-04-17 16:33:16.829927] ------> ERROR generating/optimizing candidates for example 5: CUDA out of memory. Tried to allocate 22.15 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 22.93 GiB is allocated by PyTorch, and 4.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:16.843814] ------> Finished optimizing example 6. Duration: 1.45s\n",
            "[2025-04-17 16:33:16.843866] ------> Optimizing example 7/8 (type: word)...\n",
            "[2025-04-17 16:33:18.398330] ------> ERROR generating/optimizing candidates for example 6: CUDA out of memory. Tried to allocate 23.87 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 24.65 GiB is allocated by PyTorch, and 3.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:18.412527] ------> Finished optimizing example 7. Duration: 1.57s\n",
            "[2025-04-17 16:33:18.412582] ------> Optimizing example 8/8 (type: word)...\n",
            "[2025-04-17 16:33:19.765145] ------> ERROR generating/optimizing candidates for example 7: CUDA out of memory. Tried to allocate 20.71 GiB. GPU 0 has a total capacity of 39.56 GiB of which 11.27 GiB is free. Process 266738 has 28.28 GiB memory in use. Of the allocated memory 21.49 GiB is allocated by PyTorch, and 6.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Using original.\n",
            "[2025-04-17 16:33:19.779829] ------> Finished optimizing example 8. Duration: 1.37s\n",
            "[2025-04-17 16:33:19.779921] ----> Finished optimization type 'word'. Avg human-score: 0.9975. Total detector queries: 0. Duration: 10.62s\n",
            "[2025-04-17 16:33:19.780164] Iter 6: -> Finished example optimization. Avg human-score: 0.9975. Duration: 10.62s\n",
            "[2025-04-17 16:33:19.780197] Iter 6: -> Evaluating and saving new prompt (eval_and_save)...\n",
            "[2025-04-17 16:33:19.780211] --> Starting eval_and_save for step 6...\n",
            "[2025-04-17 16:33:19.780420] -> Starting evaluate_prompt for 32 examples...\n",
            "[2025-04-17 16:33:19.781393] -> Generating eval outputs via LLM (32 examples)...\n",
            "[2025-04-17 16:34:49.198207] -> Calling detector for 32 generated texts...\n",
            "[2025-04-17 16:34:49.339149] -> Detector finished.\n",
            "[2025-04-17 16:34:49.339328] -> Finished evaluate_prompt. U=0.7094, Acc=28.12%. Duration: 89.56s\n",
            "[2025-04-17 16:34:49.339744] --> Saving generated texts for step 6...\n",
            "[2025-04-17 16:34:49.339814] ---> Saving text list '6' to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/text_6.tsv...\n",
            "[2025-04-17 16:34:49.345764] --> Saving prompt/examples for step 6...\n",
            "[2025-04-17 16:34:49.345833] ---> Saving step '6' data to /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6...\n",
            "[2025-04-17 16:34:49.352897] ---> Step '6' data saved successfully.\n",
            "[2025-04-17 16:34:49.353088] --> Score in step 6 (0.7094) not better than best (0.7458).\n",
            "[2025-04-17 16:34:49.353122] --> Finished eval_and_save for step 6. Duration: 89.57s\n",
            "[2025-04-17 16:34:49.353267] Iter 6: -> Finished evaluation and saving. Best score updated: False. Duration: 89.57s\n",
            "[2025-04-17 16:34:49.353285] === Finished Training Iteration 6. Iteration Duration: 100.19s ===\n",
            "Main Training Loop: 100% 6/6 [11:39<00:00, 116.64s/it]\n",
            "\n",
            "[2025-04-17 16:34:49.353635] Finished training loop after 6 iterations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SICO test"
      ],
      "metadata": {
        "id": "U2yxlRAtDrU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SICO\n",
        "\n",
        "print(\"Generowanie sparafrazowanych tekstów za pomocą SICO dla TEST_SAMPLE_SIZE przykładów...\")\n",
        "\n",
        "TEST_SAMPLE_SIZE=100\n",
        "\n",
        "!OPENAI_API_KEY='sk-' /usr/local/envs/chatgpt/bin/python SICO_test_gen.py \\\n",
        "    --dataset hc3_wiki \\\n",
        "    --llm chatgpt \\\n",
        "    --detector chatdetect \\\n",
        "    --task paraphrase \\\n",
        "    --incontext-size 8 \\\n",
        "    --eval-size 32 \\\n",
        "    --train-iter 6 \\\n",
        "    --test-size $TEST_SAMPLE_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05YomP8pHzlx",
        "outputId": "54d4fef8-1cda-438d-e032-62e37f7493df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SICO\n",
            "Generowanie sparafrazowanych tekstów za pomocą SICO dla TEST_SAMPLE_SIZE przykładów...\n",
            "[dataloader] Loading test input data from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv\n",
            "[dataloader] Raw test data rows loaded: 100\n",
            "Load from /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_chatdetect_eval=32_ic=8_iter=6/best_feature_ice.pkl\n",
            "OPENAI KEY: sk-proj--G...\n",
            "Start generating on test set\n",
            "100% 100/100 [05:04<00:00,  3.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "tsv_paths = {\n",
        "    \"generated_text\": \"/content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/SICO-hc3_wiki-paraphrase-chatgpt-chatdetect/generated_text.tsv\"\n",
        "#    \"logrank\": \"/content/drive/MyDrive/SICO/outputs/test_results/originality/SICO-originality-paraphrase-chatgpt-logrank/generated_text.tsv\"\n",
        "}\n",
        "\n",
        "# Katalog wyjściowy\n",
        "output_dir = \"/content/drive/MyDrive/SICO_tests\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Przetwarzanie i zapis\n",
        "for name, path in tsv_paths.items():\n",
        "    df = pd.read_csv(path, sep='\\t')\n",
        "    output_file = os.path.join(output_dir, f\"chatdetect_{name}.json\")\n",
        "\n",
        "    # Konwersja do JSON\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(df.to_dict(orient=\"records\"), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Podgląd\n",
        "    print(f\"\\nZawartość pliku test_{name}.json:\")\n",
        "    with open(output_file, 'r', encoding='utf-8') as f:\n",
        "        print(f.read()[:10000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6pVTII-Bh8Z",
        "outputId": "a59598c5-3bad-4122-cbeb-b31fad8da965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Zawartość pliku test_generated_text.json:\n",
            "[\n",
            "  {\n",
            "    \"input\": \"Understanding the functional architecture of the brain in terms of networks is becoming increasingly common. In most fMRI applications functional networks are assumed to be stationary, resulting in a single network estimated for the entire time course. However recent results suggest that the connectivity between brain regions is highly non-stationary even at rest. As a result, there is a need for new brain imaging methodologies that comprehensively account for the dynamic (i.e., non-stationary) nature of the fMRI data. In this work we propose the Smooth Incremental Graphical Lasso Estimation (SINGLE) algorithm which estimates dynamic brain networks from fMRI data. We apply the SINGLE algorithm to functional MRI data from 24 healthy patients performing a choice-response task to demonstrate the dynamic changes in network structure that accompany a simple but attentionally demanding cognitive task. Using graph theoretic measures we show that the Right Inferior Frontal Gyrus, frequently reported as playing an important role in cognitive control, dynamically changes with the task. Our results suggest that the Right Inferior Frontal Gyrus plays a fundamental role in the attention and executive function during cognitively demanding tasks and may play a key role in regulating the balance between other brain regions.\",\n",
            "    \"SICO-output\": \"The increasing interest in understanding the brain's functional architecture through network analysis has prompted the exploration of dynamic brain connectivity patterns. Traditionally, functional networks in fMRI studies are assumed to be static, resulting in a single network estimated for the entire duration of the scan. However, recent findings indicate that brain region connectivity is highly non-stationary even during resting states, necessitating novel imaging methodologies to capture this dynamic nature of fMRI data. In this study, the Smooth Incremental Graphical Lasso Estimation (SINGLE) algorithm is proposed to estimate dynamic brain networks from fMRI data. By applying the SINGLE algorithm to functional MRI data from 24 healthy individuals engaged in a choice-response task, the dynamic changes in network structure accompanying this attentionally demanding cognitive task are revealed. Through graph theoretic analyses, it is demonstrated that the Right Inferior Frontal Gyrus, known for its role in cognitive control, exhibits dynamic alterations in response to the task. These results suggest that the Right Inferior Frontal Gyrus plays a pivotal role in attention and executive function during cognitive tasks, potentially regulating the interplay between different brain regions.\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"Acoustic-prosodic entrainment describes the tendency of humans to align or adapt their speech acoustics to each other in conversation. This alignment of spoken behavior has important implications for conversational success. However, modeling the subtle nature of entrainment in spoken dialogue continues to pose a challenge. In this paper, we propose a straightforward definition for local entrainment in the speech domain and operationalize an algorithm based on this: acoustic-prosodic features that capture entrainment should be maximally different between real conversations involving two partners and sham conversations generated by randomly mixing the speaking turns from the original two conversational partners. We propose an approach for measuring local entrainment that quantifies alignment of behavior on a turn-by-turn basis, projecting the differences between interlocutors' acoustic-prosodic features for a given turn onto a discriminative feature subspace that maximizes the difference between real and sham conversations. We evaluate the method using the derived features to drive a classifier aiming to predict an objective measure of conversational success (i.e., low versus high), on a corpus of task-oriented conversations. The proposed entrainment approach achieves 72% classification accuracy using a Naive Bayes classifier, outperforming three previously established approaches evaluated on the same conversational corpus.\",\n",
            "    \"SICO-output\": \"Acoustic-prosodic entrainment refers to the phenomenon wherein individuals adjust their speech acoustics to align with each other during conversations, having significant implications for the success of verbal interactions. However, accurately modeling the subtle nature of entrainment in spoken dialogue remains a challenging task. This study introduces a clear definition for local entrainment in the speech domain and develops an algorithm based on this notion. The algorithm focuses on utilizing acoustic-prosodic features that exhibit maximal differences between authentic conversations involving two speakers and simulated conversations generated by randomly shuffling speaking turns from the original conversational partners. The proposed method quantifies local entrainment by measuring the alignment of behaviors on a turn-by-turn basis, projecting the disparities in acoustic-prosodic features between conversational partners onto a discriminative feature space that enhances the differentiation between real and simulated conversations. The efficacy of the approach is evaluated by utilizing the derived features to train a classifier designed to predict conversational success levels (i.e., low versus high) in a collection of task-oriented dialogues. The outcomes reveal that the proposed entrainment approach achieves a classification accuracy rate of 72% employing a Naive Bayes classifier, outperforming three existing methods evaluated on the same conversational dataset.\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"Deep sets are a promising technique for analyzing unordered sets of data. Unlike classical methods which work on ordered input sequences, deep sets view the input set as a mathematical object and apply a permutation-invariant neural network to learn a representation of the set. This allows deep sets to tackle tasks like set classification, set similarity, and even set-to-set prediction. One key advantage of deep sets is their ability to handle variable-sized sets, making them especially attractive in applications like graph embeddings and point cloud analysis. Despite their success, there remain challenges in effectively training deep sets and handling large-scale datasets. This review surveys recent progress in deep sets, identifying key theoretical and practical advancements, highlighting applications in several domains, and discussing open challenges and future directions. Overall, deep sets offer a powerful approach for learning from sets and are poised to become an increasingly important tool in data science.\",\n",
            "    \"SICO-output\": \"Deep sets are an innovative approach to analyzing unordered datasets, diverging from traditional methodologies that focus on ordered sequences. By treating the input set as a mathematical entity, deep sets leverage permutation-invariant neural networks to learn a representation of the set. This unique approach enables deep sets to address various tasks such as set classification, measuring set similarity, and even predicting set-to-set relationships. Noteworthy is the capability of deep sets to handle sets of varying sizes, rendering them particularly beneficial in domains like graph embeddings and point cloud analysis. While deep sets have shown success, challenges persist in effectively training these models and managing extensive datasets. A comprehensive review delves into recent advancements in deep sets, outlining key theoretical and practical progress, showcasing applications across diverse domains, and discussing unresolved hurdles and future trajectories. Deep sets serve as a potent tool for analyzing datasets and are poised to play a pivotal role in elevating data science practices.\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"Recently, differentiable neural architecture search methods significantly reduce the search cost by constructing a super network and relax the architecture representation by assigning architecture weights to the candidate operations. All the existing methods determine the importance of each operation directly by architecture weights. However, architecture weights cannot accurately reflect the importance of each operation; that is, the operation with the highest weight might not related to the best performance. To alleviate this deficiency, we propose a simple yet effective solution to neural architecture search, termed as exploiting operation importance for effective neural architecture search (EoiNAS), in which a new indicator is proposed to fully exploit the operation importance and guide the model search. Based on this new indicator, we propose a gradual operation pruning strategy to further improve the search efficiency and accuracy. Experimental results have demonstrated the effectiveness of the proposed method. Specifically, we achieve an error rate of 2.50\\\\% on CIFAR-10, which significantly outperforms state-of-the-art methods. When transferred to ImageNet, it achieves the top-1 error of 25.6\\\\%, comparable to the state-of-the-art performance under the mobile setting.\",\n",
            "    \"SICO-output\": \"Recently, breakthroughs in differentiable neural architecture search have revolutionized the search process by constructing a super network and using architecture weights to represent candidate operations in a relaxed manner. However, existing methods rely solely on architecture weights to determine the importance of each operation, which may not accurately reflect the operation's impact on performance. To address this limitation, a novel approach called Exploiting Operation Importance for Effective Neural Architecture Search (EoiNAS) is proposed. This method introduces a new indicator to fully leverage operation importance and guide the model search process. Additionally, a gradual operation pruning strategy is implemented to enhance search efficiency and accuracy. Empirical results showcase the effe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Detection test"
      ],
      "metadata": {
        "id": "mOVAoyR9rbnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME=\"hc3_wiki\"\n",
        "\n",
        "#METHOD_NAME=\"SICO-hc3_wiki-paraphrase-chatgpt-logrank\"\n",
        "#METHOD_NAME=\"SICO-hc3_wiki-paraphrase-chatgpt-detectgpt\"\n",
        "METHOD_NAME=\"SICO-hc3_wiki-paraphrase-chatgpt-chatdetect\"\n",
        "\n",
        "\n",
        "#DETECTOR_TO_TEST=\"logrank\"\n",
        "#DETECTOR_TO_TEST=\"detectgpt\"\n",
        "DETECTOR_TO_TEST=\"chatdetect\"\n",
        "\n",
        "print(f\"Testowanie metody '{METHOD_NAME}' na datasecie '{DATASET_NAME}' używając detektora '{DETECTOR_TO_TEST}'...\")\n",
        "\n",
        "!/usr/local/envs/chatgpt/bin/python run_test_detection.py \\\n",
        "    --dataset $DATASET_NAME \\\n",
        "    --method $METHOD_NAME \\\n",
        "    --detector $DETECTOR_TO_TEST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQlM4Y6Lrey1",
        "outputId": "f5b8b140-2f98-4bb1-dea3-17ac6146508e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testowanie metody 'SICO-hc3_wiki-paraphrase-chatgpt-chatdetect' na datasecie 'hc3_wiki' używając detektora 'chatdetect'...\n",
            "========= Dataset:hc3_wiki Method:SICO-hc3_wiki-paraphrase-chatgpt-chatdetect Detector:chatdetect ==============\n",
            "Downloading tokenizer_config.json: 100% 391/391 [00:00<00:00, 57.4kB/s]\n",
            "Downloading vocab.json: 100% 798k/798k [00:00<00:00, 1.21MB/s]\n",
            "Downloading merges.txt: 100% 456k/456k [00:00<00:00, 42.9MB/s]\n",
            "Downloading tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 4.84MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 280/280 [00:00<00:00, 106kB/s]\n",
            "Downloading config.json: 100% 858/858 [00:00<00:00, 331kB/s]\n",
            "Downloading pytorch_model.bin: 100% 499M/499M [00:01<00:00, 298MB/s]\n",
            "/usr/local/envs/chatgpt/lib/python3.8/site-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "3.00% of texts are detected as AI-gen with default threshold 0.50\n",
            "Save detection result to /content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/SICO-hc3_wiki-paraphrase-chatgpt-chatdetect/chatdetect_score.tsv\n",
            "[dataloader] Loading reference AI outputs from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv\n",
            "========= Dataset:hc3_wiki Method:orig Detector:chatdetect ==============\n",
            "38.00% of texts are detected as AI-gen with default threshold 0.50\n",
            "Save detection result to /content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/orig/chatdetect_score.tsv\n",
            "[dataloader] Loading reference human outputs from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv\n",
            "========= Dataset:hc3_wiki Method:human Detector:chatdetect ==============\n",
            "0.00% of texts are detected as AI-gen with default threshold 0.50\n",
            "Save detection result to /content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/human/chatdetect_score.tsv\n",
            "SICO: 100, AI: 100, Human: 100\n",
            "\n",
            "    Dataset: hc3_wiki, Detector: chatdetect\n",
            "    =============== ACC ==================\n",
            "    Low Threshold:  0.00043\n",
            "    AI: 95.00%\n",
            "    SICO-hc3_wiki-paraphrase-chatgpt-chatdetect: 87.00%\n",
            "    Human(FPR): 0.00%\n",
            "    --------------------------------------\n",
            "    \n",
            "    High Threshold:  0.00025\n",
            "    AI: 100.00%\n",
            "    SICO-hc3_wiki-paraphrase-chatgpt-chatdetect: 100.00%\n",
            "    Human(FPR): 0.00%\n",
            "    --------------------------------------\n",
            "    \n",
            "    ================ AUC ==================\n",
            "    Orig: 1.0000\n",
            "    SICO-hc3_wiki-paraphrase-chatgpt-chatdetect:  1.0000\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IJt-j2CNRIJ",
        "outputId": "2d7d8d8b-1791-4ece-82b4-571d78c29bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abstracts_long.tsv   creative_long.gsheet  creative_short.tsv  essays_short.tsv\n",
            "abstracts_short.tsv  creative_long.tsv\t   essays_long.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# --- KONFIGURACJA DLA TEGO PLIKU ŹRÓDŁOWEGO ---\n",
        "SOURCE_TSV_NAME = \"essays_short.tsv\"\n",
        "SOURCE_TSV_PATH = f\"/content/drive/MyDrive/data/{SOURCE_TSV_NAME}\"\n",
        "AI_COLUMN_INDEX = 2\n",
        "\n",
        "# Nazwa datasetu użytego do TRENINGU promptu SICO\n",
        "TRAINING_DATASET_NAME = \"hc3_wiki\"\n",
        "TARGET_SICO_TEST_FILE = f\"/content/drive/MyDrive/SICO/datasets/{TRAINING_DATASET_NAME}/test.tsv\"\n",
        "# ----------------------------------------------\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    if text is None: return \"\"\n",
        "    text = str(text).replace('\\n', ' ').replace('\\t', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "print(f\"--- Krok 1: Przygotowanie {TARGET_SICO_TEST_FILE} z {SOURCE_TSV_NAME} ---\", flush=True)\n",
        "try:\n",
        "\n",
        "    df_source = pd.read_csv(SOURCE_TSV_PATH, sep='\\t', header=None, low_memory=False)\n",
        "    print(f\"Wczytano {len(df_source)} wierszy z {SOURCE_TSV_NAME}.\", flush=True)\n",
        "\n",
        "    ai_texts_for_sico = []\n",
        "    for index, row in df_source.iterrows():\n",
        "        if AI_COLUMN_INDEX < len(row):\n",
        "            cleaned_ai = clean_text(row[AI_COLUMN_INDEX])\n",
        "            if cleaned_ai:\n",
        "                ai_texts_for_sico.append(cleaned_ai)\n",
        "        else:\n",
        "            print(f\"Ostrzeżenie: Wiersz {index} w {SOURCE_TSV_NAME} ma mniej niż {AI_COLUMN_INDEX+1} kolumn.\", flush=True)\n",
        "\n",
        "    if not ai_texts_for_sico:\n",
        "        raise ValueError(f\"Nie znaleziono żadnych tekstów AI w kolumnie {AI_COLUMN_INDEX} pliku {SOURCE_TSV_NAME}.\")\n",
        "\n",
        "    print(f\"Wyodrębniono {len(ai_texts_for_sico)} tekstów AI do przetworzenia.\", flush=True)\n",
        "\n",
        "    data_for_sico_tsv = []\n",
        "    for i, ai_text in enumerate(ai_texts_for_sico):\n",
        "        placeholder_input = f\"{SOURCE_TSV_NAME}_input_{i+1}\"\n",
        "        placeholder_human = \"N/A\"\n",
        "        data_for_sico_tsv.append([placeholder_input, placeholder_human, ai_text])\n",
        "\n",
        "    df_sico_test = pd.DataFrame(data_for_sico_tsv, columns=['input', 'human', 'ai'])\n",
        "    df_sico_test.to_csv(TARGET_SICO_TEST_FILE, sep='\\t', index=False, header=True, quoting=3)\n",
        "    print(f\"Zapisano {len(data_for_sico_tsv)} tekstów do {TARGET_SICO_TEST_FILE}\", flush=True)\n",
        "    print(f\"--- Krok 1 Zakończony ---\", flush=True)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"BŁĄD: Nie znaleziono pliku źródłowego: {SOURCE_TSV_PATH}\", flush=True)\n",
        "except Exception as e:\n",
        "    print(f\"BŁĄD podczas przygotowywania pliku wejściowego dla SICO: {e}\", flush=True)\n",
        "    raise e\n",
        "\n",
        "NUM_TEXTS_TO_PROCESS = len(data_for_sico_tsv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n319WdUzNTWy",
        "outputId": "79e2bd06-71bc-433a-e583-be76b1dda262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Krok 1: Przygotowanie /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv z essays_short.tsv ---\n",
            "Wczytano 101 wierszy z essays_short.tsv.\n",
            "Wyodrębniono 101 tekstów AI do przetworzenia.\n",
            "Zapisano 101 tekstów do /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv\n",
            "--- Krok 1 Zakończony ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SICO\n",
        "\n",
        "TRAINING_DATASET_NAME=\"hc3_wiki\"\n",
        "LLM_USED=\"chatgpt\"\n",
        "DETECTOR_USED=\"logrank\"\n",
        "INCONTEXT_SIZE=8\n",
        "EVAL_SIZE=32\n",
        "TRAIN_ITER=6\n",
        "\n",
        "try:\n",
        "  TEST_SAMPLE_SIZE = NUM_TEXTS_TO_PROCESS\n",
        "except NameError:\n",
        "  print(\"Nie znaleziono zmiennej NUM_TEXTS_TO_PROCESS, ustawiam domyślny TEST_SAMPLE_SIZE=10. Sprawdź!\")\n",
        "  TEST_SAMPLE_SIZE = 100\n",
        "\n",
        "SICO_OUTPUT_METHOD_NAME=f\"SICO-{TRAINING_DATASET_NAME}-paraphrase-{LLM_USED}-{DETECTOR_USED}\"\n",
        "SICO_OUTPUT_FOLDER=f\"/content/drive/MyDrive/SICO/outputs/test_results/{TRAINING_DATASET_NAME}/{SICO_OUTPUT_METHOD_NAME}\"\n",
        "SICO_GENERATED_TEXT_FILE=f\"{SICO_OUTPUT_FOLDER}/generated_text.tsv\"\n",
        "\n",
        "print(f\"--- Krok 2: Uruchamianie SICO_test_gen.py dla {TEST_SAMPLE_SIZE} tekstów ---\", flush=True)\n",
        "print(f\"Używany prompt trenowany z: dataset={TRAINING_DATASET_NAME}, llm={LLM_USED}, detector={DETECTOR_USED}\", flush=True)\n",
        "print(f\"Wyniki zostaną zapisane w: {SICO_GENERATED_TEXT_FILE}\", flush=True)\n",
        "\n",
        "!OPENAI_API_KEY='sk-proj--' /usr/local/envs/chatgpt/bin/python SICO_test_gen.py \\\n",
        "    --dataset $TRAINING_DATASET_NAME \\\n",
        "    --llm $LLM_USED \\\n",
        "    --detector $DETECTOR_USED \\\n",
        "    --task paraphrase \\\n",
        "    --incontext-size $INCONTEXT_SIZE \\\n",
        "    --eval-size $EVAL_SIZE \\\n",
        "    --train-iter $TRAIN_ITER \\\n",
        "    --test-size $TEST_SAMPLE_SIZE\n",
        "\n",
        "print(f\"--- Krok 2 Zakończony ---\", flush=True)\n",
        "!ls -l $SICO_GENERATED_TEXT_FILE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgTwrcCmRbmm",
        "outputId": "196635e5-b33a-4b72-8756-4ad6ebe60c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SICO\n",
            "--- Krok 2: Uruchamianie SICO_test_gen.py dla 101 tekstów ---\n",
            "Używany prompt trenowany z: dataset=hc3_wiki, llm=chatgpt, detector=logrank\n",
            "Wyniki zostaną zapisane w: /content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/SICO-hc3_wiki-paraphrase-chatgpt-logrank/generated_text.tsv\n",
            "[dataloader] Loading test input data from: /content/drive/MyDrive/SICO/datasets/hc3_wiki/test.tsv\n",
            "[dataloader] Raw test data rows loaded: 101\n",
            "Load from /content/drive/MyDrive/SICO/outputs/results/run_hc3_wiki_paraphrase_chatgpt_logrank_eval=32_ic=8_iter=6/best_feature_ice.pkl\n",
            "OPENAI KEY: sk-proj--G...\n",
            "Start generating on test set\n",
            "100% 101/101 [04:49<00:00,  2.87s/it]\n",
            "--- Krok 2 Zakończony ---\n",
            "-rw------- 1 root root 344004 Apr 18 10:29 /content/drive/MyDrive/SICO/outputs/test_results/hc3_wiki/SICO-hc3_wiki-paraphrase-chatgpt-logrank/generated_text.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Skrypt 1: Przetwarzanie Wyników RAFT + Detekcja SICO + Kopiowanie Wyników"
      ],
      "metadata": {
        "id": "hyoHLP8SDRMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skrypt 1: Przetwarzanie RAFT, Detekcja, Kopiowanie (Poprawione Wywołanie Detekcji)\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import csv\n",
        "import argparse\n",
        "\n",
        "print(\"--- START: Skrypt 1 (RAFT) ---\")\n",
        "\n",
        "\n",
        "SOURCE_BASENAME = \"abstracts_long\"\n",
        "SICO_DATASET_NAME = \"hc3_wiki\"\n",
        "ORIGINAL_AI_TSV_PATH = f\"/content/drive/MyDrive/data/Oryginal/{SOURCE_BASENAME}.tsv\"\n",
        "ORIGINAL_AI_COL_INDEX = 2\n",
        "RAFT_RESULTS_CSV_PATH = f\"/content/drive/MyDrive/data/RAFT_modification/{SOURCE_BASENAME}.csv\"\n",
        "RAFT_SAMPLED_COL_NAME = \"sampled_text\"\n",
        "DETECTOR_TO_TEST = \"detectgpt\"\n",
        "\n",
        "RAFT_METHOD_NAME = f\"RAFT-Paraphrased-{SOURCE_BASENAME}\"\n",
        "SICO_METHOD_RESULTS_DIR = f\"/content/drive/MyDrive/SICO/outputs/test_results/{SICO_DATASET_NAME}/{RAFT_METHOD_NAME}\"\n",
        "SICO_GENERATED_TEXT_TSV = os.path.join(SICO_METHOD_RESULTS_DIR, \"generated_text.tsv\")\n",
        "FINAL_RESULTS_DIR = \"/content/drive/MyDrive/data/Final_results/\"\n",
        "PYTHON_INTERPRETER = \"/usr/local/envs/chatgpt/bin/python\"\n",
        "SICO_DETECTION_SCRIPT = \"/content/drive/MyDrive/SICO/run_test_detection.py\"\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    if text is None: return \"\"\n",
        "    if isinstance(text, float) and pd.isna(text): return \"\"\n",
        "    text = str(text).replace('\\n', ' ').replace('\\t', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "conversion_success = False\n",
        "detection_success = False\n",
        "processing_error = None\n",
        "\n",
        "try:\n",
        "    # --- Krok 1b: Tworzenie folderu wynikowego SICO ---\n",
        "    print(f\"\\n--- Krok 1: Tworzenie folderu wynikowego ---\", flush=True)\n",
        "    os.makedirs(SICO_METHOD_RESULTS_DIR, exist_ok=True)\n",
        "    print(f\"Folder: {SICO_METHOD_RESULTS_DIR}\", flush=True)\n",
        "\n",
        "    # --- Krok 2: Konwersja RAFT CSV + Oryginał AI do SICO TSV ---\n",
        "    print(f\"\\n--- Krok 2: Konwersja RAFT CSV + Oryginał AI do SICO TSV ---\", flush=True)\n",
        "    print(f\"Źródło oryginałów AI: {ORIGINAL_AI_TSV_PATH} (kol: {ORIGINAL_AI_COL_INDEX})\", flush=True)\n",
        "    print(f\"Źródło wyników RAFT: {RAFT_RESULTS_CSV_PATH} (kol: {RAFT_SAMPLED_COL_NAME})\", flush=True)\n",
        "    print(f\"Plik wyjściowy TSV: {SICO_GENERATED_TEXT_TSV}\", flush=True)\n",
        "    original_ai_texts = []\n",
        "    raft_sampled_texts = []\n",
        "    df_source = pd.read_csv(ORIGINAL_AI_TSV_PATH, sep='\\t', header=0, low_memory=False, quoting=3)\n",
        "    if ORIGINAL_AI_COL_INDEX >= len(df_source.columns): raise IndexError(f\"Index kolumny {ORIGINAL_AI_COL_INDEX} poza zakresem dla {ORIGINAL_AI_TSV_PATH}.\")\n",
        "    for text in df_source.iloc[:, ORIGINAL_AI_COL_INDEX]:\n",
        "        cleaned = clean_text(text)\n",
        "        if cleaned: original_ai_texts.append(cleaned)\n",
        "    print(f\"Wczytano {len(original_ai_texts)} oryginalnych tekstów AI.\", flush=True)\n",
        "    if not original_ai_texts: raise ValueError(\"Brak tekstów AI.\")\n",
        "    df_raft = pd.read_csv(RAFT_RESULTS_CSV_PATH, header=0, skiprows=[1])\n",
        "    if RAFT_SAMPLED_COL_NAME not in df_raft.columns: raise KeyError(f\"Brak kolumny '{RAFT_SAMPLED_COL_NAME}' w {RAFT_RESULTS_CSV_PATH}\")\n",
        "    print(f\"Wczytano {len(df_raft)} poprawnych wierszy danych z pliku RAFT.\", flush=True)\n",
        "    for text in df_raft[RAFT_SAMPLED_COL_NAME]: raft_sampled_texts.append(clean_text(text))\n",
        "    if len(original_ai_texts) != len(raft_sampled_texts):\n",
        "        print(f\"OSTRZEŻENIE: Liczba oryginałów AI ({len(original_ai_texts)}) != wyniki RAFT ({len(raft_sampled_texts)}). Używam min({min(len(original_ai_texts), len(raft_sampled_texts))}) par.\", flush=True)\n",
        "        min_len = min(len(original_ai_texts), len(raft_sampled_texts))\n",
        "        if min_len == 0: raise ValueError(\"Brak wspólnych danych.\")\n",
        "        combined_data = list(zip(original_ai_texts[:min_len], raft_sampled_texts[:min_len]))\n",
        "    else:\n",
        "        combined_data = list(zip(original_ai_texts, raft_sampled_texts))\n",
        "    print(f\"Sparowano {len(combined_data)} rekordów.\", flush=True)\n",
        "    filtered_combined_data = [pair for pair in combined_data if pair[1]]\n",
        "    if len(filtered_combined_data) != len(combined_data): print(f\"Usunięto {len(combined_data) - len(filtered_combined_data)} par z pustym tekstem RAFT.\", flush=True)\n",
        "    if not filtered_combined_data: raise ValueError(\"Brak poprawnych par danych po filtrowaniu.\")\n",
        "    df_output = pd.DataFrame(filtered_combined_data, columns=['input', 'SICO-output'])\n",
        "    df_output.to_csv(SICO_GENERATED_TEXT_TSV, sep='\\t', index=False, header=True, quoting=csv.QUOTE_MINIMAL) # Zmieniono quoting\n",
        "    print(f\"Zapisano pomyślnie {len(filtered_combined_data)} rekordów do {SICO_GENERATED_TEXT_TSV}\", flush=True)\n",
        "    conversion_success = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"BŁĄD KROKU 2 (Konwersja): {e}\", flush=True)\n",
        "    processing_error = e\n",
        "\n",
        "# --- Krok 3: Uruchomienie Testu Detekcji SICO (Poprawione Wywołanie) ---\n",
        "if conversion_success:\n",
        "    print(f\"\\n--- Krok 3: Uruchamianie testu detekcji SICO ---\", flush=True)\n",
        "    print(f\"Metoda: {RAFT_METHOD_NAME}\", flush=True)\n",
        "    print(f\"Detektor: {DETECTOR_TO_TEST}\", flush=True)\n",
        "\n",
        "    env_prefix = \"export LC_ALL=C.UTF-8; export LANG=C.UTF-8; \"\n",
        "\n",
        "    cmd_list = [\n",
        "        PYTHON_INTERPRETER, SICO_DETECTION_SCRIPT,\n",
        "        \"--dataset\", SICO_DATASET_NAME,\n",
        "        \"--method\", RAFT_METHOD_NAME,\n",
        "        \"--detector\", DETECTOR_TO_TEST\n",
        "    ]\n",
        "    # Tworzymy pełną komendę jako string dla powłoki\n",
        "    command_string = env_prefix + \" \".join(cmd_list)\n",
        "\n",
        "    print(f\"Running command: {command_string}\")\n",
        "    os.system(command_string)\n",
        "    print(\"\\nTest detekcji SICO wykonany (sprawdź wyjście powyżej).\", flush=True)\n",
        "\n",
        "    sico_score_file_path = os.path.join(SICO_METHOD_RESULTS_DIR, f\"{DETECTOR_TO_TEST}_score.tsv\")\n",
        "    if os.path.exists(sico_score_file_path):\n",
        "        print(\"Plik z wynikami detekcji został znaleziony.\", flush=True)\n",
        "        detection_success = True\n",
        "    else:\n",
        "        print(f\"BŁĄD: Plik z wynikami detekcji {sico_score_file_path} nie został utworzony.\", flush=True)\n",
        "        processing_error = Exception(f\"SICO Detection script failed to create score file for {DETECTOR_TO_TEST}\")\n",
        "        detection_success = False\n",
        "else:\n",
        "    print(\"\\nPominięto Krok 3 z powodu błędu w Kroku 2.\", flush=True)\n",
        "    detection_success = False\n",
        "\n",
        "# --- Krok 4: Kopiowanie Wyników Detekcji ---\n",
        "if detection_success:\n",
        "    print(f\"\\n--- Krok 4: Kopiowanie wyników detekcji ---\", flush=True)\n",
        "    sico_score_file_path = os.path.join(SICO_METHOD_RESULTS_DIR, f\"{DETECTOR_TO_TEST}_score.tsv\")\n",
        "    final_filename = f\"{SOURCE_BASENAME}_RAFT_{DETECTOR_TO_TEST}_scores.tsv\"\n",
        "    final_destination_path = os.path.join(FINAL_RESULTS_DIR, final_filename)\n",
        "    print(f\"Kopiowanie z: {sico_score_file_path}\")\n",
        "    print(f\"Do: {final_destination_path}\")\n",
        "    try:\n",
        "        os.makedirs(FINAL_RESULTS_DIR, exist_ok=True)\n",
        "        if os.path.exists(sico_score_file_path):\n",
        "             shutil.copy2(sico_score_file_path, final_destination_path)\n",
        "             print(f\"Plik z wynikami skopiowany jako: {final_filename}\", flush=True)\n",
        "        else:\n",
        "             print(f\"BŁĄD: Nie znaleziono pliku źródłowego z wynikami detekcji: {sico_score_file_path}\", flush=True)\n",
        "             processing_error = FileNotFoundError(f\"Score file not found: {sico_score_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"BŁĄD podczas kopiowania pliku wyników: {e}\", flush=True)\n",
        "        processing_error = e\n",
        "else:\n",
        "    print(\"\\nPominięto Krok 4 z powodu wcześniejszych błędów.\", flush=True)\n",
        "\n",
        "if 'processing_error' in locals() and processing_error:\n",
        "  print(f\"\\n--- Skrypt 1 zakończony z BŁĘDEM: {processing_error} ---\")\n",
        "else:\n",
        "  print(\"\\n--- Skrypt 1 zakończony ---\")"
      ],
      "metadata": {
        "id": "c10AiAwLDQt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Skrypt 2: Przygotowanie i Detekcja Oryginalnych Tekstów AI"
      ],
      "metadata": {
        "id": "yCY_1lW2DUuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skrypt 2: Detekcja Oryginalnych AI (Poprawione Wywołanie Detekcji)\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import csv\n",
        "import argparse\n",
        "\n",
        "print(\"--- START: Skrypt 2 (Oryginał AI) ---\")\n",
        "\n",
        "# --- 1. KONFIGURACJA ---\n",
        "SOURCE_BASENAME = \"abstracts_long\"\n",
        "SICO_DATASET_NAME = \"hc3_wiki\"\n",
        "ORIGINAL_AI_TSV_PATH = f\"/content/drive/MyDrive/data/Oryginal/{SOURCE_BASENAME}.tsv\"\n",
        "ORIGINAL_AI_COL_INDEX = 2\n",
        "DETECTOR_TO_TEST = \"detectgpt\"\n",
        "\n",
        "ORIG_AI_METHOD_NAME = f\"Original-AI-{SOURCE_BASENAME}\"\n",
        "SICO_METHOD_RESULTS_DIR = f\"/content/drive/MyDrive/SICO/outputs/test_results/{SICO_DATASET_NAME}/{ORIG_AI_METHOD_NAME}\"\n",
        "SICO_GENERATED_TEXT_TSV = os.path.join(SICO_METHOD_RESULTS_DIR, \"generated_text.tsv\")\n",
        "FINAL_RESULTS_DIR = \"/content/drive/MyDrive/data/Final_results/\"\n",
        "PYTHON_INTERPRETER = \"/usr/local/envs/chatgpt/bin/python\"\n",
        "SICO_DETECTION_SCRIPT = \"/content/drive/MyDrive/SICO/run_test_detection.py\"\n",
        "\n",
        "def clean_text(text):\n",
        "    if text is None: return \"\"\n",
        "    if isinstance(text, float) and pd.isna(text): return \"\"\n",
        "    text = str(text).replace('\\n', ' ').replace('\\t', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "conversion_success = False\n",
        "detection_success = False\n",
        "processing_error = None\n",
        "\n",
        "try:\n",
        "    # --- Krok 1b: Tworzenie folderu wynikowego SICO ---\n",
        "    print(f\"\\n--- Krok 1: Tworzenie folderu wynikowego ---\", flush=True)\n",
        "    os.makedirs(SICO_METHOD_RESULTS_DIR, exist_ok=True)\n",
        "    print(f\"Folder: {SICO_METHOD_RESULTS_DIR}\", flush=True)\n",
        "\n",
        "    # --- Krok 2: Przygotowanie SICO TSV dla Oryginalnych AI ---\n",
        "    print(f\"\\n--- Krok 2: Przygotowanie SICO TSV dla Oryginalnych AI ---\", flush=True)\n",
        "    print(f\"Źródło oryginałów AI: {ORIGINAL_AI_TSV_PATH} (kol: {ORIGINAL_AI_COL_INDEX})\", flush=True)\n",
        "    print(f\"Plik wyjściowy TSV: {SICO_GENERATED_TEXT_TSV}\", flush=True)\n",
        "\n",
        "    original_ai_texts = []\n",
        "    df_source = pd.read_csv(ORIGINAL_AI_TSV_PATH, sep='\\t', header=0, low_memory=False, quoting=3)\n",
        "    if ORIGINAL_AI_COL_INDEX >= len(df_source.columns): raise IndexError(f\"Index kolumny {ORIGINAL_AI_COL_INDEX} poza zakresem dla {ORIGINAL_AI_TSV_PATH}.\")\n",
        "    for text in df_source.iloc[:, ORIGINAL_AI_COL_INDEX]:\n",
        "        cleaned = clean_text(text)\n",
        "        if cleaned: original_ai_texts.append(cleaned)\n",
        "    print(f\"Wczytano {len(original_ai_texts)} oryginalnych tekstów AI.\", flush=True)\n",
        "    if not original_ai_texts: raise ValueError(\"Brak tekstów AI.\")\n",
        "\n",
        "    data_for_sico_tsv = [[f\"orig_input_{i}\", ai_text] for i, ai_text in enumerate(original_ai_texts)]\n",
        "    df_output = pd.DataFrame(data_for_sico_tsv, columns=['input', 'SICO-output'])\n",
        "    df_output.to_csv(SICO_GENERATED_TEXT_TSV, sep='\\t', index=False, header=True, quoting=csv.QUOTE_MINIMAL) # Zmieniono quoting\n",
        "    print(f\"Zapisano pomyślnie {len(data_for_sico_tsv)} rekordów do {SICO_GENERATED_TEXT_TSV}\", flush=True)\n",
        "    conversion_success = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"BŁĄD KROKU 2 (Przygotowanie Oryg. AI): {e}\", flush=True)\n",
        "    processing_error = e\n",
        "\n",
        "# --- Krok 3: Uruchomienie Testu Detekcji SICO  ---\n",
        "if conversion_success:\n",
        "    print(f\"\\n--- Krok 3: Uruchamianie testu detekcji SICO ---\", flush=True)\n",
        "    print(f\"Metoda: {ORIG_AI_METHOD_NAME}\", flush=True)\n",
        "    print(f\"Detektor: {DETECTOR_TO_TEST}\", flush=True)\n",
        "\n",
        "    env_prefix = \"export LC_ALL=C.UTF-8; export LANG=C.UTF-8; \"\n",
        "\n",
        "    cmd_list = [\n",
        "        PYTHON_INTERPRETER, SICO_DETECTION_SCRIPT,\n",
        "        \"--dataset\", SICO_DATASET_NAME,\n",
        "        \"--method\", ORIG_AI_METHOD_NAME,\n",
        "        \"--detector\", DETECTOR_TO_TEST\n",
        "    ]\n",
        "    command_string = env_prefix + \" \".join(cmd_list)\n",
        "\n",
        "    print(f\"Running command: {command_string}\")\n",
        "    os.system(command_string)\n",
        "    print(\"\\nTest detekcji SICO wykonany (sprawdź wyjście powyżej).\", flush=True)\n",
        "\n",
        "    sico_score_file_path = os.path.join(SICO_METHOD_RESULTS_DIR, f\"{DETECTOR_TO_TEST}_score.tsv\")\n",
        "    if os.path.exists(sico_score_file_path):\n",
        "        print(\"Plik z wynikami detekcji został znaleziony.\", flush=True)\n",
        "        detection_success = True\n",
        "    else:\n",
        "        print(f\"BŁĄD: Plik z wynikami detekcji {sico_score_file_path} nie został utworzony.\", flush=True)\n",
        "        processing_error = Exception(f\"SICO Detection script failed to create score file for {DETECTOR_TO_TEST}\")\n",
        "        detection_success = False\n",
        "else:\n",
        "    print(\"\\nPominięto Krok 3 z powodu błędu w Kroku 2.\", flush=True)\n",
        "    detection_success = False\n",
        "\n",
        "# --- Krok 4: Kopiowanie Wyników Detekcji ---\n",
        "if detection_success:\n",
        "    print(f\"\\n--- Krok 4: Kopiowanie wyników detekcji ---\", flush=True)\n",
        "    sico_score_file_path = os.path.join(SICO_METHOD_RESULTS_DIR, f\"{DETECTOR_TO_TEST}_score.tsv\")\n",
        "    final_filename = f\"{SOURCE_BASENAME}_Original_AI_{DETECTOR_TO_TEST}_scores.tsv\"\n",
        "    final_destination_path = os.path.join(FINAL_RESULTS_DIR, final_filename)\n",
        "    print(f\"Kopiowanie z: {sico_score_file_path}\")\n",
        "    print(f\"Do: {final_destination_path}\")\n",
        "    try:\n",
        "        os.makedirs(FINAL_RESULTS_DIR, exist_ok=True)\n",
        "        if os.path.exists(sico_score_file_path):\n",
        "             shutil.copy2(sico_score_file_path, final_destination_path)\n",
        "             print(f\"Plik z wynikami skopiowany jako: {final_filename}\", flush=True)\n",
        "        else:\n",
        "             print(f\"BŁĄD: Nie znaleziono pliku źródłowego z wynikami detekcji: {sico_score_file_path}\", flush=True)\n",
        "             processing_error = FileNotFoundError(f\"Score file not found: {sico_score_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"BŁĄD podczas kopiowania pliku wyników: {e}\", flush=True)\n",
        "        processing_error = e\n",
        "else:\n",
        "    print(\"\\nPominięto Krok 4 z powodu wcześniejszych błędów.\", flush=True)\n",
        "\n",
        "if 'processing_error' in locals() and processing_error:\n",
        "  print(f\"\\n--- Skrypt 2 zakończony z BŁĘDEM: {processing_error} ---\")\n",
        "else:\n",
        "  print(\"\\n--- Skrypt 2 zakończony ---\")"
      ],
      "metadata": {
        "id": "sVJC_8CGDXdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zewstawienie wyników"
      ],
      "metadata": {
        "id": "UbQz11tMX7o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, zipfile, tempfile, glob\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "\n",
        "# 0. PROGI KLASYFIKACJI\n",
        "THRESHOLDS = {\n",
        "    \"detectgpt\": 0.90,   # AI  ⇢ score >= 0.90\n",
        "    \"logrank\" : -1.40,   # AI  ⇢ score >= –1.40\n",
        "    \"chatdetect\": 0.50   # AI  ⇢ score >= 0.50\n",
        "}\n",
        "\n",
        "\n",
        "ZIP_PATH = \"/content/drive-download-20250420T145331Z-001.zip\"\n",
        "workdir   = tempfile.mkdtemp(prefix=\"exp_\")\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, \"r\") as zf:\n",
        "    zf.extractall(workdir)\n",
        "\n",
        "# ------------------------------------------------------------------ #\n",
        "# 2. WYSZUKIWANIE wszystkich *_scores.tsv\n",
        "# ------------------------------------------------------------------ #\n",
        "tsv_files = glob.glob(os.path.join(workdir, \"**\", \"*_scores.tsv\"), recursive=True)\n",
        "assert tsv_files, \"Nie znaleziono plików *_scores.tsv ‑ sprawdź strukturę archiwum!\"\n",
        "\n",
        "\n",
        "pat = re.compile(\n",
        "    r\"(?P<domain>abstracts|essays|creative)_\"           # domena\n",
        "    r\"(?P<length>short|long)_\"                          # długość\n",
        "    r\"(?P<variant>Original_AI|RAFT)_\"                   # wariant\n",
        "    r\"(?P<detector>[^_]+)_scores\\.tsv$\"                 # detektor\n",
        ")\n",
        "\n",
        "\n",
        "records = []\n",
        "for path in tsv_files:\n",
        "    m = pat.search(os.path.basename(path))\n",
        "    if not m:\n",
        "        print(f\"[WARN] Pomijam niepasujący plik {path}\")\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"score\"])\n",
        "    meta = m.groupdict()\n",
        "    meta[\"n\"] = len(df)\n",
        "    meta[\"scores\"] = df[\"score\"].values\n",
        "    records.append(meta)\n",
        "\n",
        "rows = []\n",
        "for rec in records:\n",
        "    for s in rec.pop(\"scores\"):\n",
        "        rows.append({**rec, \"score\": s})\n",
        "\n",
        "df_all = pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "df_all[\"label\"] = df_all[\"variant\"].map({\"Original_AI\": 1, \"RAFT\": 0})\n",
        "\n",
        "\n",
        "def agg_metrics(sub):\n",
        "    scores = sub[\"score\"].values\n",
        "    labels = sub[\"label\"].values\n",
        "    det    = sub.name[2]\n",
        "    thr    = THRESHOLDS.get(det, 0.5)\n",
        "\n",
        "    preds = (scores >= thr).astype(int)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, scores)\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return pd.Series({\n",
        "        \"mean_score\": round(scores.mean(), 4),\n",
        "        \"AUC\"       : round(auc, 4) if auc == auc else auc,\n",
        "        \"F1\"        : round(f1_score(labels, preds, zero_division=0), 4),\n",
        "        \"n\"         : len(scores)\n",
        "    })\n",
        "\n",
        "summary_df = (\n",
        "    df_all\n",
        "    .groupby([\"domain\", \"length\", \"detector\"])\n",
        "    .apply(agg_metrics)\n",
        "    .reset_index()\n",
        "    .sort_values([\"domain\", \"length\", \"detector\"])\n",
        ")\n",
        "\n",
        "print(\"\\n===  PODSUMOWANIE  (mean_score, AUC, F1)  ===\")\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "summary_df.to_csv(\"AUC_F1_summary.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "VleCfIN_uxX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Me3o6bKmyzRz",
        "RAooKGRGztMV",
        "hp2CHREayqA5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}